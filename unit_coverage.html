
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>infra: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">shellbox/internal/infra/bastion.go (0.0%)</option>
				
				<option value="file1">shellbox/internal/infra/clients.go (0.0%)</option>
				
				<option value="file2">shellbox/internal/infra/constants.go (63.6%)</option>
				
				<option value="file3">shellbox/internal/infra/golden_snapshot.go (0.0%)</option>
				
				<option value="file4">shellbox/internal/infra/instances.go (0.0%)</option>
				
				<option value="file5">shellbox/internal/infra/logger.go (80.0%)</option>
				
				<option value="file6">shellbox/internal/infra/network.go (0.0%)</option>
				
				<option value="file7">shellbox/internal/infra/pool.go (0.0%)</option>
				
				<option value="file8">shellbox/internal/infra/qemu_manager.go (0.0%)</option>
				
				<option value="file9">shellbox/internal/infra/resource_allocator.go (0.0%)</option>
				
				<option value="file10">shellbox/internal/infra/resource_graph_queries.go (0.0%)</option>
				
				<option value="file11">shellbox/internal/infra/resource_naming.go (95.0%)</option>
				
				<option value="file12">shellbox/internal/infra/retry.go (93.8%)</option>
				
				<option value="file13">shellbox/internal/infra/tables.go (0.0%)</option>
				
				<option value="file14">shellbox/internal/infra/volumes.go (0.0%)</option>
				
				<option value="file15">shellbox/internal/sshutil/ssh.go (0.0%)</option>
				
				<option value="file16">shellbox/internal/test/config.go (46.3%)</option>
				
				<option value="file17">shellbox/internal/test/golden_utils.go (0.0%)</option>
				
				<option value="file18">shellbox/internal/test/setup.go (6.9%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">package infra

import (
        "context"
        "encoding/base64"
        "fmt"
        "log/slog"
        "os"
        "os/exec"
        "strings"
        "time"

        "shellbox/internal/sshutil"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/authorization/armauthorization"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
        "github.com/google/uuid"
)

const bastionSetupScript = `#!/bin/bash
sudo apt-get update -y
sudo apt-get upgrade -y

# Security hardening
ufw allow OpenSSH
ufw --force enable

# Bastion-specific setup
mkdir -p /etc/ssh/sshd_config.d/
echo "PermitUserEnvironment yes" &gt; /etc/ssh/sshd_config.d/shellbox.conf
systemctl reload sshd

# Create shellbox directory
mkdir -p /home/\${admin_user}`

func GenerateBastionInitScript() (string, error) <span class="cov0" title="0">{
        fullScript := fmt.Sprintf(`#cloud-config
runcmd:
- %s`, bastionSetupScript)
        return base64.StdEncoding.EncodeToString([]byte(fullScript)), nil
}</span>

// DefaultBastionConfig returns a default configuration for bastion deployment
func DefaultBastionConfig() *VMConfig <span class="cov0" title="0">{
        return &amp;VMConfig{
                AdminUsername: "shellbox",
                VMSize:        string(armcompute.VirtualMachineSizeTypesStandardD2SV3),
        }
}</span>

func compileBastionServer() error <span class="cov0" title="0">{
        if err := exec.Command("go", "build", "-o", "/tmp/server", "./cmd/server").Run(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to compile server binary: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func createBastionPublicIP(ctx context.Context, clients *AzureClients) (*armnetwork.PublicIPAddress, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        ipPoller, err := clients.PublicIPClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, namer.BastionPublicIPName(), armnetwork.PublicIPAddress{
                Location: to.Ptr(Location),
                SKU: &amp;armnetwork.PublicIPAddressSKU{
                        Name: to.Ptr(armnetwork.PublicIPAddressSKUNameStandard),
                },
                Properties: &amp;armnetwork.PublicIPAddressPropertiesFormat{
                        PublicIPAllocationMethod: to.Ptr(armnetwork.IPAllocationMethodStatic),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start public IP creation: %w", err)
        }</span>
        <span class="cov0" title="0">res, err := ipPoller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to poll IP creation: %w", err)
        }</span>
        <span class="cov0" title="0">return &amp;res.PublicIPAddress, nil</span>
}

func createBastionNIC(ctx context.Context, clients *AzureClients, publicIPID *string) (*armnetwork.Interface, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        nicPoller, err := clients.NICClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, namer.BastionNICName(), armnetwork.Interface{
                Location: to.Ptr(Location),
                Properties: &amp;armnetwork.InterfacePropertiesFormat{
                        IPConfigurations: []*armnetwork.InterfaceIPConfiguration{
                                {
                                        Name: to.Ptr("ipconfig1"),
                                        Properties: &amp;armnetwork.InterfaceIPConfigurationPropertiesFormat{
                                                Subnet: &amp;armnetwork.Subnet{
                                                        ID: to.Ptr(clients.BastionSubnetID),
                                                },
                                                PrivateIPAllocationMethod: to.Ptr(armnetwork.IPAllocationMethodDynamic),
                                                PublicIPAddress: &amp;armnetwork.PublicIPAddress{
                                                        ID: publicIPID,
                                                },
                                        },
                                },
                        },
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start NIC creation: %w", err)
        }</span>
        <span class="cov0" title="0">res, err := nicPoller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to poll NIC creation: %w", err)
        }</span>
        <span class="cov0" title="0">return &amp;res.Interface, nil</span>
}

func createBastionVM(ctx context.Context, clients *AzureClients, config *VMConfig, nicID string, customData string) (*armcompute.VirtualMachine, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        vmPoller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, namer.BastionVMName(), armcompute.VirtualMachine{
                Location: to.Ptr(Location),
                Identity: &amp;armcompute.VirtualMachineIdentity{
                        Type: to.Ptr(armcompute.ResourceIdentityTypeSystemAssigned),
                },
                Properties: &amp;armcompute.VirtualMachineProperties{
                        HardwareProfile: &amp;armcompute.HardwareProfile{
                                VMSize: to.Ptr(armcompute.VirtualMachineSizeTypes(config.VMSize)),
                        },
                        StorageProfile: &amp;armcompute.StorageProfile{
                                ImageReference: &amp;armcompute.ImageReference{
                                        Publisher: to.Ptr(VMPublisher),
                                        Offer:     to.Ptr(VMOffer),
                                        SKU:       to.Ptr(VMSku),
                                        Version:   to.Ptr(VMVersion),
                                },
                                OSDisk: &amp;armcompute.OSDisk{
                                        Name:         to.Ptr(namer.BastionOSDiskName()),
                                        CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesFromImage),
                                        ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                                                StorageAccountType: to.Ptr(armcompute.StorageAccountTypesPremiumLRS),
                                        },
                                },
                        },
                        OSProfile: &amp;armcompute.OSProfile{
                                ComputerName:  to.Ptr(namer.BastionComputerName()),
                                AdminUsername: to.Ptr(config.AdminUsername),
                                CustomData:    to.Ptr(customData),
                                LinuxConfiguration: &amp;armcompute.LinuxConfiguration{
                                        DisablePasswordAuthentication: to.Ptr(true),
                                        SSH: &amp;armcompute.SSHConfiguration{
                                                PublicKeys: []*armcompute.SSHPublicKey{
                                                        {
                                                                Path:    to.Ptr(fmt.Sprintf("/home/%s/.ssh/authorized_keys", config.AdminUsername)),
                                                                KeyData: to.Ptr(config.SSHPublicKey),
                                                        },
                                                },
                                        },
                                },
                        },
                        NetworkProfile: &amp;armcompute.NetworkProfile{
                                NetworkInterfaces: []*armcompute.NetworkInterfaceReference{
                                        {
                                                ID: to.Ptr(nicID),
                                                Properties: &amp;armcompute.NetworkInterfaceReferenceProperties{
                                                        Primary: to.Ptr(true),
                                                },
                                        },
                                },
                        },
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start bastion VM creation: %w", err)
        }</span>

        <span class="cov0" title="0">vm, err := vmPoller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create bastion VM: %w", err)
        }</span>

        <span class="cov0" title="0">if vm.Identity == nil || vm.Identity.PrincipalID == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("VM managed identity not found after creation")
        }</span>

        <span class="cov0" title="0">return &amp;vm.VirtualMachine, nil</span>
}

// copyServerBinary compiles and copies the server binary to the bastion host.
// Uses retry with timeout because the bastion may still be initializing and
// might not be ready to accept SSH connections immediately.
func copyServerBinary(ctx context.Context, config *VMConfig, publicIPAddress string) error <span class="cov0" title="0">{
        remotePath := fmt.Sprintf("/home/%s/server", config.AdminUsername)
        return RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return sshutil.CopyFile(ctx, "/tmp/server", remotePath, config.AdminUsername, publicIPAddress)
        }</span>, 5*time.Minute, 5*time.Second, "copy server binary to bastion")
}

// copyTableStorageConfig creates a configuration file with Table Storage connection string
// and copies it to the bastion host. This is called after copyServerBinary
// because we don't need to retry - if copyServerBinary succeeded, the bastion
// is already initialized and accepting connections.
func copyTableStorageConfig(ctx context.Context, clients *AzureClients, config *VMConfig, publicIPAddress string) error <span class="cov0" title="0">{
        tableStorageConfigContent := fmt.Sprintf(`{"connectionString": "%s"}`, clients.TableStorageConnectionString)

        // Create temporary local file
        tempFile := "/tmp/tablestorage.json"
        if err := os.WriteFile(tempFile, []byte(tableStorageConfigContent), 0o600); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create temporary Table Storage config file: %w", err)
        }</span>
        <span class="cov0" title="0">defer os.Remove(tempFile) // Clean up when done

        // Copy to bastion
        remoteConfigPath := fmt.Sprintf("/home/%s/%s", config.AdminUsername, tableStorageConfigFile)
        if err := sshutil.CopyFile(ctx, tempFile, remoteConfigPath, config.AdminUsername, publicIPAddress); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to copy Table Storage config to bastion: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func startServerOnBastion(ctx context.Context, config *VMConfig, publicIPAddress string, resourceGroupSuffix string) error <span class="cov0" title="0">{
        command := fmt.Sprintf("nohup /home/%s/server %s &gt; /home/%s/server.log 2&gt;&amp;1 &amp;", config.AdminUsername, resourceGroupSuffix, config.AdminUsername)
        return RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return sshutil.ExecuteCommand(ctx, command, config.AdminUsername, publicIPAddress)
        }</span>, 2*time.Minute, 5*time.Second, "start server on bastion")
}

func getBastionRoleID(subscriptionID string) string <span class="cov0" title="0">{
        // Use built-in Contributor role which can manage all resources including disks
        return fmt.Sprintf("/subscriptions/%s/providers/Microsoft.Authorization/roleDefinitions/b24988ac-6180-42a0-ab88-20f7382dd24c", subscriptionID)
}</span>

func assignRoleToVM(ctx context.Context, clients *AzureClients, principalID *string) error <span class="cov0" title="0">{
        roleDefID := getBastionRoleID(clients.SubscriptionID)
        guid := uuid.New().String()
        scope := fmt.Sprintf("/subscriptions/%s", clients.SubscriptionID)

        return RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                _, err := clients.RoleClient.Create(ctx,
                        scope,
                        guid,
                        armauthorization.RoleAssignmentCreateParameters{
                                Properties: &amp;armauthorization.RoleAssignmentProperties{
                                        PrincipalID:      principalID,
                                        RoleDefinitionID: to.Ptr(roleDefID),
                                },
                        }, nil)
                if err != nil </span><span class="cov0" title="0">{
                        // Treat PrincipalNotFound as retryable without logging error
                        if strings.Contains(err.Error(), "PrincipalNotFound") </span><span class="cov0" title="0">{
                                return fmt.Errorf("principal not found, retrying")
                        }</span>
                        <span class="cov0" title="0">return fmt.Errorf("creating role assignment: %w", err)</span>
                }
                <span class="cov0" title="0">return nil</span>
        }, 2*time.Minute, 10*time.Second, "assign role to bastion VM")
}

// DeployBastion creates a bastion host in the bastion subnet and returns its public IP
func DeployBastion(ctx context.Context, clients *AzureClients, config *VMConfig) string <span class="cov0" title="0">{
        logger := slog.New(slog.NewJSONHandler(os.Stdout, &amp;slog.HandlerOptions{
                Level: slog.LevelInfo,
        }))

        if err := compileBastionServer(); err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to compile server binary", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">publicIP, err := createBastionPublicIP(ctx, clients)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create public IP", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">nic, err := createBastionNIC(ctx, clients, publicIP.ID)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create NIC", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">customData, err := GenerateBastionInitScript()
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to generate init script", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">vm, err := createBastionVM(ctx, clients, config, *nic.ID, customData)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create bastion VM", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">if err := assignRoleToVM(ctx, clients, vm.Identity.PrincipalID); err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to assign role to VM", "error", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err := copyServerBinary(ctx, config, *publicIP.Properties.IPAddress); err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to copy server binary", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">if err := copyTableStorageConfig(ctx, clients, config, *publicIP.Properties.IPAddress); err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to copy Table Storage config", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">if err := startServerOnBastion(ctx, config, *publicIP.Properties.IPAddress, clients.ResourceGroupSuffix); err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to start server on bastion", "error", err)
                os.Exit(1)
        }</span>

        <span class="cov0" title="0">return *publicIP.Properties.IPAddress</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">package infra

import (
        "context"
        "encoding/json"
        "fmt"
        "log/slog"
        "os"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore"
        "github.com/Azure/azure-sdk-for-go/sdk/azidentity"
        "github.com/Azure/azure-sdk-for-go/sdk/data/aztables"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/authorization/armauthorization"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resourcegraph/armresourcegraph"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armresources"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armsubscriptions"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/storage/armstorage"
)

func FatalOnError(err error, message string) <span class="cov0" title="0">{
        if err != nil </span><span class="cov0" title="0">{
                slog.Error(message, "error", err)
                os.Exit(1)
        }</span>
}

func createAzureClients(clients *AzureClients) <span class="cov0" title="0">{
        var err error

        clients.ResourceClient, err = armresources.NewResourceGroupsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create resource group client")

        clients.NetworkClient, err = armnetwork.NewVirtualNetworksClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create network client")

        clients.NSGClient, err = armnetwork.NewSecurityGroupsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create NSG client")

        clients.SubnetsClient, err = armnetwork.NewSubnetsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create subnets client")

        clients.PublicIPClient, err = armnetwork.NewPublicIPAddressesClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create Public IP client")

        clients.NICClient, err = armnetwork.NewInterfacesClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create interfaces client")

        clients.ComputeClient, err = armcompute.NewVirtualMachinesClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create compute client")

        clients.StorageClient, err = armstorage.NewAccountsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create storage client")

        clients.RoleClient, err = armauthorization.NewRoleAssignmentsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create role assignments client")

        clients.DisksClient, err = armcompute.NewDisksClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create disks client")

        clients.SnapshotsClient, err = armcompute.NewSnapshotsClient(clients.SubscriptionID, clients.Cred, nil)
        FatalOnError(err, "failed to create snapshots client")

        clients.ResourceGraphClient, err = armresourcegraph.NewClient(clients.Cred, nil)
        FatalOnError(err, "failed to create resource graph client")
}</span>

func createTableClient(clients *AzureClients) <span class="cov0" title="0">{
        // If connection string is not already set, try to read from config file
        if clients.TableStorageConnectionString == "" </span><span class="cov0" title="0">{
                if err := readTableStorageConfig(clients); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("Table Storage config not available", "error", err)
                        return
                }</span>
        }

        // If we still don't have a connection string, can't create client
        <span class="cov0" title="0">if clients.TableStorageConnectionString == "" </span><span class="cov0" title="0">{
                slog.Warn("Table Storage connection string not available")
                return
        }</span>

        <span class="cov0" title="0">client, err := aztables.NewServiceClientFromConnectionString(clients.TableStorageConnectionString, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to create table storage client", "error", err)
                return
        }</span>
        <span class="cov0" title="0">clients.TableClient = client</span>
}

func waitForRoleAssignment(ctx context.Context, cred azcore.TokenCredential) string <span class="cov0" title="0">{
        var subscriptionID string
        err := RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                client, err := armsubscriptions.NewClient(cred, nil)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">pager := client.NewListPager(nil)
                page, err := pager.NextPage(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if len(page.Value) == 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("no subscriptions found")
                }</span>
                <span class="cov0" title="0">subscriptionID = *page.Value[0].SubscriptionID
                return nil</span>
        }, 5*time.Minute, 5*time.Second, "verify role assignment")
        <span class="cov0" title="0">FatalOnError(err, "role assignment verification failed")
        return subscriptionID</span>
}

// readTableStorageConfig reads Table Storage connection string from the config file
func readTableStorageConfig(clients *AzureClients) error <span class="cov0" title="0">{
        data, err := os.ReadFile(tableStorageConfigFile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to read Table Storage config file: %w", err)
        }</span>

        <span class="cov0" title="0">var config struct {
                ConnectionString string `json:"connectionString"`
        }

        if err := json.Unmarshal(data, &amp;config); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse Table Storage config: %w", err)
        }</span>

        <span class="cov0" title="0">clients.TableStorageConnectionString = config.ConnectionString
        return nil</span>
}

// NewAzureClients creates all Azure clients using credential-based subscription ID discovery
func NewAzureClients(suffix string, useAzureCli bool) *AzureClients <span class="cov0" title="0">{
        var cred azcore.TokenCredential
        var err error

        if !useAzureCli </span><span class="cov0" title="0">{
                cred, err = azidentity.NewManagedIdentityCredential(nil)
                FatalOnError(err, "failed to create managed identity credential")
        }</span> else<span class="cov0" title="0"> {
                // Use Azure CLI credentials
                cred, err = azidentity.NewAzureCLICredential(nil)
                FatalOnError(err, "failed to create Azure CLI credential")
        }</span>

        <span class="cov0" title="0">slog.Info("waiting for role assignment to propagate")
        ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
        defer cancel()
        subscriptionID := waitForRoleAssignment(ctx, cred)
        slog.Info("role assignment active")

        // Initialize clients with parallel client creation
        namer := NewResourceNamer(suffix)
        clients := &amp;AzureClients{
                Cred:                cred,
                SubscriptionID:      subscriptionID,
                Suffix:              suffix,
                ResourceGroupSuffix: suffix,
                ResourceGroupName:   namer.ResourceGroup(),
                BastionSubnetID:     "",
                BoxesSubnetID:       "",
        }

        createAzureClients(clients)
        createTableClient(clients)

        return clients</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">package infra

import (
        "crypto/sha256"
        "encoding/hex"
        "fmt"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"
        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
)

// Resource group configuration
const (
        Location = "westus2"
)

// Network configuration
const (
        vnetAddressSpace = "10.0.0.0/8"

        // Subnet CIDR configuration
        bastionSubnetCIDR = "10.0.0.0/24"
        boxesSubnetCIDR   = "10.1.0.0/16"
)

// Table Storage configuration
const (
        tableStorageConfigFile = ".tablestorage.json"

        // Shared storage account for testing (no suffix)
        TestingStorageAccountBaseName = "shellboxtest536567"

        // Table name base constants (will be suffixed for test isolation)
        tableEventLogBase         = "EventLog"
        tableResourceRegistryBase = "ResourceRegistry"

        // Legacy constants for backward compatibility
        tableEventLog         = "EventLog"
        tableResourceRegistry = "ResourceRegistry"
)

// VM configuration
const (
        // VM image configuration
        VMPublisher = "Canonical"
        VMOffer     = "0001-com-ubuntu-server-jammy"
        VMSku       = "22_04-lts-gen2"
        VMVersion   = "latest"

        // SSH port configuration
        BastionSSHPort = 2222

        // Box SSH configuration
        BoxSSHPort = 2222

        // SSH key paths
        DeploymentSSHKeyPath = "$HOME/.ssh/id_ed25519"      // For deployment from dev machine
        BastionSSHKeyPath    = "/home/shellbox/.ssh/id_rsa" // For bastion host operations

        // VM default configuration
        VMSize        = "Standard_D8s_v3" // 8 vCPUs, 32GB RAM for good nested VM performance
        AdminUsername = "shellbox"
)

// Resource roles
const (
        ResourceRoleInstance = "instance"
        ResourceRoleVolume   = "volume"
        ResourceRoleTemp     = "temp"
)

// Resource statuses
const (
        ResourceStatusFree      = "free"
        ResourceStatusConnected = "connected"
        ResourceStatusAttached  = "attached"
)

// Tag keys for pool resources
const (
        TagKeyRole     = "shellbox:role"
        TagKeyStatus   = "shellbox:status"
        TagKeyCreated  = "shellbox:created"
        TagKeyLastUsed = "shellbox:lastused"
)

// Tag keys for golden snapshot resources (separate namespace)
const (
        GoldenTagKeyRole    = "golden:role"
        GoldenTagKeyPurpose = "golden:purpose"
        GoldenTagKeyCreated = "golden:created"
        GoldenTagKeyStage   = "golden:stage"
)

// Azure resource types for Resource Graph queries
const (
        AzureResourceTypeVM   = "microsoft.compute/virtualmachines"
        AzureResourceTypeDisk = "microsoft.compute/disks"
)

// Query and disk constants
const (
        MaxQueryResults      = 10
        DefaultVolumeSizeGB  = 100
        GoldenSnapshotPrefix = "golden-snapshot"
)

// Persistent resource group for golden snapshots (shared across deployments)
const (
        GoldenSnapshotResourceGroup = "shellbox-golden-images"
)

// Pool configuration constants for production
const (
        DefaultMinFreeInstances  = 5
        DefaultMaxFreeInstances  = 10
        DefaultMaxTotalInstances = 100
        DefaultMinFreeVolumes    = 20
        DefaultMaxFreeVolumes    = 50
        DefaultMaxTotalVolumes   = 500
        DefaultCheckInterval     = 1 * time.Minute
        DefaultScaleDownCooldown = 10 * time.Minute
)

// Pool configuration constants for development
const (
        DevMinFreeInstances  = 1
        DevMaxFreeInstances  = 2
        DevMaxTotalInstances = 5
        DevMinFreeVolumes    = 2
        DevMaxFreeVolumes    = 5
        DevMaxTotalVolumes   = 20
        DevCheckInterval     = 30 * time.Second
        DevScaleDownCooldown = 2 * time.Minute
)

// Default polling options for Azure operations
var DefaultPollOptions = runtime.PollUntilDoneOptions{
        Frequency: 2 * time.Second,
}

// createNSGRule helper function to reduce boilerplate
func createNSGRule(name, protocol, srcAddr, dstAddr, dstPort string, access armnetwork.SecurityRuleAccess, priority int32, direction armnetwork.SecurityRuleDirection) *armnetwork.SecurityRule <span class="cov8" title="1">{
        return &amp;armnetwork.SecurityRule{
                Name: to.Ptr(name),
                Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                        Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocol(protocol)),
                        SourceAddressPrefix:      to.Ptr(srcAddr),
                        SourcePortRange:          to.Ptr("*"),
                        DestinationAddressPrefix: to.Ptr(dstAddr),
                        DestinationPortRange:     to.Ptr(dstPort),
                        Access:                   to.Ptr(access),
                        Priority:                 to.Ptr(priority),
                        Direction:                to.Ptr(direction),
                },
        }
}</span>

// NSG Rules configuration
var BastionNSGRules = []*armnetwork.SecurityRule{
        createNSGRule("AllowSSHFromInternet", "Tcp", "Internet", "*", "22", armnetwork.SecurityRuleAccessAllow, 100, armnetwork.SecurityRuleDirectionInbound),
        createNSGRule("AllowCustomSSHFromInternet", "Tcp", "Internet", "*", fmt.Sprintf("%d", BastionSSHPort), armnetwork.SecurityRuleAccessAllow, 110, armnetwork.SecurityRuleDirectionInbound),
        createNSGRule("AllowHTTPSFromInternet", "Tcp", "Internet", "*", "443", armnetwork.SecurityRuleAccessAllow, 120, armnetwork.SecurityRuleDirectionInbound),
        createNSGRule("AllowToBoxesSubnet", "*", "*", boxesSubnetCIDR, "*", armnetwork.SecurityRuleAccessAllow, 100, armnetwork.SecurityRuleDirectionOutbound),
        createNSGRule("AllowToInternet", "*", "*", "Internet", "*", armnetwork.SecurityRuleAccessAllow, 110, armnetwork.SecurityRuleDirectionOutbound),
}

func FormatConfig(suffix string) string <span class="cov8" title="1">{
        namer := NewResourceNamer(suffix)
        return fmt.Sprintf(`Network Configuration:
  VNet: %s (%s)
  Bastion Subnet: %s (%s)
  Boxes Subnet: %s (%s)
  NSG Rules:
%s
  Resource Group Suffix: %s`,
                namer.VNetName(), vnetAddressSpace,
                namer.BastionSubnetName(), bastionSubnetCIDR,
                namer.BoxesSubnetName(), boxesSubnetCIDR,
                formatNSGRules(BastionNSGRules),
                suffix)
}</span>

func formatNSGRules(rules []*armnetwork.SecurityRule) string <span class="cov8" title="1">{
        var result string
        for _, rule := range rules </span><span class="cov8" title="1">{
                result += fmt.Sprintf("    - %s: %s %s-&gt;%s (%s)\n",
                        *rule.Name,
                        *rule.Properties.Access,
                        *rule.Properties.SourceAddressPrefix,
                        *rule.Properties.DestinationAddressPrefix,
                        *rule.Properties.Direction)
        }</span>
        <span class="cov8" title="1">return result</span>
}

func GenerateConfigHash(suffix string) (string, error) <span class="cov0" title="0">{
        hashInput := FormatConfig(suffix)

        hasher := sha256.New()
        hasher.Write([]byte(hashInput))
        return hex.EncodeToString(hasher.Sum(nil))[:8], nil
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">package infra

import (
        "context"
        "crypto/sha256"
        "encoding/base64"
        "encoding/hex"
        "fmt"
        "log/slog"
        "os/exec"
        "strings"
        "time"

        "shellbox/internal/sshutil"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armresources"
)

// QEMUScriptConfig holds configuration for generating QEMU initialization scripts
type QEMUScriptConfig struct {
        SSHPublicKey  string
        WorkingDir    string // "~" for home directory, "/mnt/userdata" for data volume
        SSHPort       int
        MountDataDisk bool // Whether to mount and format a data disk first
}

// GenerateQEMUInitScript creates a QEMU initialization script with the given configuration
func GenerateQEMUInitScript(config QEMUScriptConfig) (string, error) <span class="cov0" title="0">{
        var mountSection string
        if config.MountDataDisk </span><span class="cov0" title="0">{
                mountSection = `
# Wait for data disk to be available
while [ ! -e /dev/disk/azure/scsi1/lun0 ]; do
    echo "Waiting for data disk..."
    sleep 5
done

# Format and mount data disk
sudo mkfs.ext4 /dev/disk/azure/scsi1/lun0
sudo mkdir -p /mnt/userdata
sudo mount /dev/disk/azure/scsi1/lun0 /mnt/userdata
echo '/dev/disk/azure/scsi1/lun0 /mnt/userdata ext4 defaults 0 2' | sudo tee -a /etc/fstab
`
        }</span>

        <span class="cov0" title="0">var ownershipSection string
        if config.WorkingDir == "/mnt/userdata" </span><span class="cov0" title="0">{
                ownershipSection = `
# Set ownership for data volume
sudo chown -R $USER:$USER /mnt/userdata/
`
        }</span>

        <span class="cov0" title="0">script := fmt.Sprintf(`#!/bin/bash

echo "\$nrconf{restart} = 'a';" | sudo tee /etc/needrestart/conf.d/50-autorestart.conf
%s
# Install QEMU and dependencies
sudo apt update
sudo apt install qemu-utils qemu-system-x86 qemu-kvm qemu-system libvirt-daemon-system libvirt-clients bridge-utils genisoimage whois libguestfs-tools socat -y

sudo usermod -aG kvm,libvirt $USER
sudo systemctl enable --now libvirtd

# Create QEMU environment
mkdir -p %s/qemu-disks %s/qemu-memory
%s
# Download and prepare Ubuntu image
cd %s/
wget https://cloud-images.ubuntu.com/releases/24.04/release/ubuntu-24.04-server-cloudimg-amd64.img
cp ubuntu-24.04-server-cloudimg-amd64.img qemu-disks/ubuntu-base.qcow2
qemu-img resize qemu-disks/ubuntu-base.qcow2 64G

# Create cloud-init configuration for SSH access
cat &gt; user-data &lt;&lt; 'EOFMARKER'
#cloud-config
hostname: ubuntu
users:
  - name: ubuntu
    ssh_authorized_keys:
      - '%s'
    shell: /bin/bash
    sudo: ALL=(ALL) NOPASSWD:ALL
package_update: true
packages:
  - openssh-server
ssh_pwauth: false
ssh:
  install-server: yes
  permit_root_login: false
  password_authentication: false
EOFMARKER

cat &gt; meta-data &lt;&lt; 'EOFMARKER'
instance-id: ubuntu-inst-1
local-hostname: ubuntu
EOFMARKER

genisoimage -output qemu-disks/cloud-init.iso -volid cidata -joliet -rock user-data meta-data

# Start QEMU VM with SSH-ready configuration and monitor socket
sudo qemu-system-x86_64 \
   -enable-kvm \
   -m 24G \
   -mem-prealloc \
   -mem-path %s/qemu-memory/ubuntu-mem \
   -smp 8 \
   -cpu host \
   -drive file=%s/qemu-disks/ubuntu-base.qcow2,format=qcow2 \
   -drive file=%s/qemu-disks/cloud-init.iso,format=raw \
   -nographic \
   -monitor unix:/tmp/qemu-monitor.sock,server,nowait \
   -nic user,model=virtio,hostfwd=tcp::%d-:22,dns=8.8.8.8`,
                mountSection,
                config.WorkingDir, config.WorkingDir,
                ownershipSection,
                config.WorkingDir,
                config.SSHPublicKey,
                config.WorkingDir,
                config.WorkingDir, config.WorkingDir,
                config.SSHPort)

        return base64.StdEncoding.EncodeToString([]byte(script)), nil</span>
}

// GoldenSnapshotInfo contains information about the created golden snapshot
type GoldenSnapshotInfo struct {
        Name         string
        ResourceID   string
        Location     string
        CreatedTime  time.Time
        SizeGB       int32
        SourceDiskID string
}

// CreateGoldenSnapshotIfNotExists creates a golden snapshot containing a pre-configured QEMU environment.
// This snapshot serves as the base for all user volumes, ensuring consistent and fast provisioning.
// The function is idempotent - it will find and return existing snapshots rather than creating duplicates.
// Golden snapshots are stored in a persistent resource group to avoid recreation between deployments.
func CreateGoldenSnapshotIfNotExists(ctx context.Context, clients *AzureClients, _, _ string) (*GoldenSnapshotInfo, error) <span class="cov0" title="0">{
        // Ensure the persistent resource group exists
        if err := ensureGoldenSnapshotResourceGroup(ctx, clients); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to ensure golden snapshot resource group: %w", err)
        }</span>

        // Generate content-based snapshot name for this QEMU configuration
        <span class="cov0" title="0">snapshotName, err := generateGoldenSnapshotName()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate snapshot name: %w", err)
        }</span>

        // Check if golden snapshot already exists in the persistent resource group
        <span class="cov0" title="0">slog.Info("Checking for existing golden snapshot", "snapshotName", snapshotName, "resourceGroup", GoldenSnapshotResourceGroup)
        existing, err := clients.SnapshotsClient.Get(ctx, GoldenSnapshotResourceGroup, snapshotName, nil)
        if err == nil </span><span class="cov0" title="0">{
                slog.Info("Found existing golden snapshot", "snapshotName", snapshotName)
                return &amp;GoldenSnapshotInfo{
                        Name:        *existing.Name,
                        ResourceID:  *existing.ID,
                        Location:    *existing.Location,
                        CreatedTime: *existing.Properties.TimeCreated,
                        SizeGB:      *existing.Properties.DiskSizeGB,
                }, nil
        }</span>

        <span class="cov0" title="0">slog.Info("Golden snapshot not found, creating new one", "snapshotName", snapshotName)

        // Create temporary box VM with data volume for QEMU setup
        tempBoxName := fmt.Sprintf("temp-golden-%d", time.Now().Unix())
        slog.Info("Creating temporary box VM", "tempBoxName", tempBoxName)

        tempBox, err := createBoxWithDataVolume(ctx, clients, GoldenSnapshotResourceGroup, tempBoxName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create temporary box for golden snapshot: %w", err)
        }</span>

        // Wait for the VM to be ready and QEMU setup to complete
        <span class="cov0" title="0">slog.Info("Waiting for QEMU setup to complete on temporary box")
        if err := waitForQEMUSetup(ctx, clients, tempBox); err != nil </span><span class="cov0" title="0">{
                // Cleanup temp resources on failure
                if cleanupErr := DeleteInstance(ctx, clients, GoldenSnapshotResourceGroup, tempBoxName); cleanupErr != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to cleanup temporary box during error recovery", "error", cleanupErr)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("failed waiting for QEMU setup: %w", err)</span>
        }

        // Create snapshot from the data volume in the persistent resource group
        <span class="cov0" title="0">slog.Info("Creating snapshot from data volume")
        snapshotInfo, err := createSnapshotFromDataVolume(ctx, clients, GoldenSnapshotResourceGroup, snapshotName, tempBox.DataDiskID)
        if err != nil </span><span class="cov0" title="0">{
                // Cleanup temp resources on failure
                if cleanupErr := DeleteInstance(ctx, clients, GoldenSnapshotResourceGroup, tempBoxName); cleanupErr != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to cleanup temporary box during error recovery", "error", cleanupErr)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("failed to create snapshot: %w", err)</span>
        }

        // Cleanup temporary resources
        <span class="cov0" title="0">slog.Info("Cleaning up temporary resources")
        if err := DeleteInstance(ctx, clients, GoldenSnapshotResourceGroup, tempBoxName); err != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to cleanup temporary box", "tempBoxName", tempBoxName, "error", err)
                // Don't fail the operation - snapshot was created successfully
        }</span>

        <span class="cov0" title="0">slog.Info("Golden snapshot created successfully", "snapshotName", snapshotName)
        return snapshotInfo, nil</span>
}

// tempBoxInfo holds information about a temporary box created for golden snapshot
type tempBoxInfo struct {
        VMName     string
        DataDiskID string
        PrivateIP  string
        PublicIP   string
        NICName    string
        NSGName    string
        DiskName   string
}

// createBoxWithDataVolume creates a temporary box VM with a data volume for QEMU setup
func createBoxWithDataVolume(ctx context.Context, clients *AzureClients, resourceGroupName, vmName string) (*tempBoxInfo, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(extractSuffix(resourceGroupName))

        // Create data volume using golden-specific tagging
        dataDiskName := fmt.Sprintf("%s-data", vmName)
        now := time.Now().UTC()

        // Use separate disk creation to avoid pool tag namespace
        diskParams := armcompute.Disk{
                Location: to.Ptr(Location),
                Properties: &amp;armcompute.DiskProperties{
                        DiskSizeGB: to.Ptr(int32(DefaultVolumeSizeGB)),
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption: to.Ptr(armcompute.DiskCreateOptionEmpty),
                        },
                },
                Tags: map[string]*string{
                        GoldenTagKeyRole:    to.Ptr("temp-data-disk"),
                        GoldenTagKeyPurpose: to.Ptr("golden-snapshot-creation"),
                        GoldenTagKeyCreated: to.Ptr(now.Format(time.RFC3339)),
                        GoldenTagKeyStage:   to.Ptr("creating"),
                },
        }

        // Create data disk directly with golden-specific tags
        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, resourceGroupName, dataDiskName, diskParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start data volume creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create data volume: %w", err)
        }</span>

        <span class="cov0" title="0">volumeInfo := &amp;VolumeInfo{
                Name:       *result.Name,
                ResourceID: *result.ID,
                Location:   *result.Location,
                SizeGB:     *result.Properties.DiskSizeGB,
        }

        // Use existing box creation functions but with a custom boxID
        boxID := vmName // Use vmName as boxID for temp box
        nsgName := namer.BoxNSGName(boxID)
        nicName := namer.BoxNICName(boxID)

        // Create NSG using existing function
        nsgResult, err := createInstanceNSG(ctx, clients, nsgName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create NSG: %w", err)
        }</span>

        // Create NIC using existing function
        <span class="cov0" title="0">nicResult, err := createInstanceNIC(ctx, clients, nicName, nsgResult.ID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create NIC: %w", err)
        }</span>

        // Load SSH key for the temporary VM
        <span class="cov0" title="0">_, sshPublicKey, err := sshutil.LoadKeyPair(BastionSSHKeyPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load SSH key: %w", err)
        }</span>

        // Create VM with data disk attached using modified function
        <span class="cov0" title="0">_, err = createBoxVMWithDataDisk(ctx, clients, resourceGroupName, vmName, *nicResult.ID, volumeInfo.ResourceID, sshPublicKey)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create VM: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;tempBoxInfo{
                VMName:     vmName,
                DataDiskID: volumeInfo.ResourceID,
                PrivateIP:  *nicResult.Properties.IPConfigurations[0].Properties.PrivateIPAddress,
                NICName:    nicName,
                NSGName:    nsgName,
                DiskName:   dataDiskName,
        }, nil</span>
}

// waitForQEMUSetup waits for the QEMU VM to be accessible via SSH on port 2222
func waitForQEMUSetup(ctx context.Context, _ *AzureClients, tempBox *tempBoxInfo) error <span class="cov0" title="0">{
        slog.Info("Waiting for QEMU VM to be SSH-ready", "vmName", tempBox.VMName, "privateIP", tempBox.PrivateIP)

        // Test SSH connectivity to the QEMU VM - this is the definitive test
        slog.Info("Testing SSH connectivity to QEMU VM", "port", BoxSSHPort)
        return RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                // Test SSH connection directly to the QEMU VM from bastion
                // We need to execute this test from the bastion, not from within the instance
                // Since sshutil.ExecuteCommand is for remote execution, let's execute locally
                cmd := exec.CommandContext(ctx, "ssh",
                        "-o", "ConnectTimeout=5",
                        "-o", "StrictHostKeyChecking=no",
                        "-p", fmt.Sprintf("%d", BoxSSHPort),
                        fmt.Sprintf("ubuntu@%s", tempBox.PrivateIP),
                        "echo 'SSH test successful'")
                if output, err := cmd.CombinedOutput(); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("QEMU VM SSH not yet ready: %w: %s", err, string(output))
                }</span>

                // Save the QEMU VM state and cleanly shut down to preserve the SSH-ready state
                <span class="cov0" title="0">slog.Info("QEMU VM SSH confirmed working, saving VM state")
                saveCmd := `echo -e "savevm ssh-ready\nquit" | sudo socat - UNIX-CONNECT:/tmp/qemu-monitor.sock`
                stopErr := sshutil.ExecuteCommand(ctx, saveCmd, AdminUsername, tempBox.PrivateIP)
                if stopErr != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to save QEMU VM state", "error", stopErr)
                        // Fallback to force quit if savevm fails
                        fallbackErr := sshutil.ExecuteCommand(ctx, "sudo pkill qemu-system-x86_64", AdminUsername, tempBox.PrivateIP)
                        if fallbackErr != nil </span><span class="cov0" title="0">{
                                slog.Warn("Fallback pkill also failed", "error", fallbackErr)
                        }</span>
                }

                <span class="cov0" title="0">slog.Info("QEMU VM SSH-ready state prepared", "vmName", tempBox.VMName)
                return nil</span>
        }, 15*time.Minute, 30*time.Second, "QEMU VM SSH connectivity")
}

// createSnapshotFromDataVolume creates a snapshot from the specified data volume
func createSnapshotFromDataVolume(ctx context.Context, clients *AzureClients, resourceGroupName, snapshotName, dataDiskID string) (*GoldenSnapshotInfo, error) <span class="cov0" title="0">{
        slog.Info("Creating snapshot", "snapshotName", snapshotName, "dataDiskID", dataDiskID)

        snapshot, err := clients.SnapshotsClient.BeginCreateOrUpdate(ctx, resourceGroupName, snapshotName, armcompute.Snapshot{
                Location: to.Ptr(Location),
                Properties: &amp;armcompute.SnapshotProperties{
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption:     to.Ptr(armcompute.DiskCreateOptionCopy),
                                SourceResourceID: to.Ptr(dataDiskID),
                        },
                },
                Tags: map[string]*string{
                        GoldenTagKeyRole:    to.Ptr("golden-snapshot"),
                        GoldenTagKeyPurpose: to.Ptr("qemu-base-image"),
                        GoldenTagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                        GoldenTagKeyStage:   to.Ptr("ready"),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create snapshot: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := snapshot.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed waiting for snapshot creation: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;GoldenSnapshotInfo{
                Name:         *result.Name,
                ResourceID:   *result.ID,
                Location:     *result.Location,
                CreatedTime:  *result.Properties.TimeCreated,
                SizeGB:       *result.Properties.DiskSizeGB,
                SourceDiskID: dataDiskID,
        }, nil</span>
}

// createBoxVMWithDataDisk creates a VM with both OS and data disks attached
func createBoxVMWithDataDisk(ctx context.Context, clients *AzureClients, resourceGroupName, vmName, nicID, dataDiskID, sshPublicKey string) (*armcompute.VirtualMachine, error) <span class="cov0" title="0">{
        // Generate initialization script for data volume setup
        initScript, err := generateDataVolumeInitScript()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to generate data volume init script: %w", err)
        }</span>

        <span class="cov0" title="0">vmParams := armcompute.VirtualMachine{
                Location: to.Ptr(Location),
                Properties: &amp;armcompute.VirtualMachineProperties{
                        HardwareProfile: &amp;armcompute.HardwareProfile{
                                VMSize: to.Ptr(armcompute.VirtualMachineSizeTypes(VMSize)),
                        },
                        StorageProfile: &amp;armcompute.StorageProfile{
                                ImageReference: &amp;armcompute.ImageReference{
                                        Publisher: to.Ptr(VMPublisher),
                                        Offer:     to.Ptr(VMOffer),
                                        SKU:       to.Ptr(VMSku),
                                        Version:   to.Ptr(VMVersion),
                                },
                                OSDisk: &amp;armcompute.OSDisk{
                                        Name:         to.Ptr(fmt.Sprintf("%s-os", vmName)),
                                        CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesFromImage),
                                        ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                                                StorageAccountType: to.Ptr(armcompute.StorageAccountTypesPremiumLRS),
                                        },
                                },
                                DataDisks: []*armcompute.DataDisk{
                                        {
                                                Name:         to.Ptr(extractDiskNameFromID(dataDiskID)),
                                                CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesAttach),
                                                Lun:          to.Ptr[int32](0),
                                                ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                                                        ID: to.Ptr(dataDiskID),
                                                },
                                        },
                                },
                        },
                        OSProfile: &amp;armcompute.OSProfile{
                                ComputerName:  to.Ptr(fmt.Sprintf("temp-%s", vmName)),
                                AdminUsername: to.Ptr(AdminUsername),
                                CustomData:    to.Ptr(initScript),
                                LinuxConfiguration: &amp;armcompute.LinuxConfiguration{
                                        DisablePasswordAuthentication: to.Ptr(true),
                                        SSH: &amp;armcompute.SSHConfiguration{
                                                PublicKeys: []*armcompute.SSHPublicKey{
                                                        {
                                                                Path:    to.Ptr(fmt.Sprintf("/home/%s/.ssh/authorized_keys", AdminUsername)),
                                                                KeyData: to.Ptr(sshPublicKey),
                                                        },
                                                },
                                        },
                                },
                        },
                        NetworkProfile: &amp;armcompute.NetworkProfile{
                                NetworkInterfaces: []*armcompute.NetworkInterfaceReference{
                                        {
                                                ID: to.Ptr(nicID),
                                        },
                                },
                        },
                },
                Tags: map[string]*string{
                        GoldenTagKeyRole:    to.Ptr("temp-vm"),
                        GoldenTagKeyPurpose: to.Ptr("golden-snapshot-creation"),
                        GoldenTagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                        GoldenTagKeyStage:   to.Ptr("creating"),
                },
        }

        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, resourceGroupName, vmName, vmParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting VM creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating VM: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;result.VirtualMachine, nil</span>
}

// generateDataVolumeInitScript creates an init script that sets up and starts QEMU VM on the data volume
func generateDataVolumeInitScript() (string, error) <span class="cov0" title="0">{
        // Load SSH key for the golden snapshot QEMU VM
        _, sshPublicKey, err := sshutil.LoadKeyPair(BastionSSHKeyPath)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to load SSH key: %w", err)
        }</span>

        // Use unified QEMU script generation with data volume configuration
        <span class="cov0" title="0">config := QEMUScriptConfig{
                SSHPublicKey:  sshPublicKey,
                WorkingDir:    "/mnt/userdata",
                SSHPort:       BoxSSHPort,
                MountDataDisk: true,
        }

        scriptContent, err := GenerateQEMUInitScript(config)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to generate unified QEMU script: %w", err)
        }</span>

        // Return the script as-is - SSH connectivity test is sufficient
        <span class="cov0" title="0">return scriptContent, nil</span>
}

// extractDiskNameFromID extracts the disk name from a full Azure resource ID
func extractDiskNameFromID(diskID string) string <span class="cov0" title="0">{
        parts := strings.Split(diskID, "/")
        return parts[len(parts)-1]
}</span>

// extractSuffix extracts the suffix from a resource group name
func extractSuffix(resourceGroupName string) string <span class="cov0" title="0">{
        // Assumes resource group name format: "shellbox-&lt;suffix&gt;"
        const prefix = "shellbox-"
        if len(resourceGroupName) &gt; len(prefix) </span><span class="cov0" title="0">{
                return resourceGroupName[len(prefix):]
        }</span>
        <span class="cov0" title="0">return resourceGroupName</span>
}

// ensureGoldenSnapshotResourceGroup creates the persistent resource group for golden snapshots if it doesn't exist
func ensureGoldenSnapshotResourceGroup(ctx context.Context, clients *AzureClients) error <span class="cov0" title="0">{
        slog.Info("Ensuring persistent resource group exists", "resourceGroup", GoldenSnapshotResourceGroup)

        // Check if resource group already exists
        _, err := clients.ResourceClient.Get(ctx, GoldenSnapshotResourceGroup, nil)
        if err == nil </span><span class="cov0" title="0">{
                slog.Info("Persistent resource group already exists", "resourceGroup", GoldenSnapshotResourceGroup)
                return nil
        }</span>

        // Create the resource group
        <span class="cov0" title="0">slog.Info("Creating persistent resource group", "resourceGroup", GoldenSnapshotResourceGroup)
        _, err = clients.ResourceClient.CreateOrUpdate(ctx, GoldenSnapshotResourceGroup, armresources.ResourceGroup{
                Location: to.Ptr(Location),
                Tags: map[string]*string{
                        GoldenTagKeyPurpose: to.Ptr("golden-snapshots"),
                        GoldenTagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                        GoldenTagKeyRole:    to.Ptr("persistent-resource-group"),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create persistent resource group: %w", err)
        }</span>

        <span class="cov0" title="0">slog.Info("Created persistent resource group", "resourceGroup", GoldenSnapshotResourceGroup)
        return nil</span>
}

// generateGoldenSnapshotName creates a content-based name for the golden snapshot
// This allows us to detect when the QEMU configuration changes and a new snapshot is needed
func generateGoldenSnapshotName() (string, error) <span class="cov0" title="0">{
        // Generate a sample QEMU script to hash its content
        config := QEMUScriptConfig{
                SSHPublicKey:  "sample-key-for-hashing",
                WorkingDir:    "/mnt/userdata",
                SSHPort:       BoxSSHPort,
                MountDataDisk: true,
        }

        scriptContent, err := GenerateQEMUInitScript(config)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to generate script for hashing: %w", err)
        }</span>

        // Hash the script content to create a unique identifier
        <span class="cov0" title="0">hasher := sha256.New()
        hasher.Write([]byte(scriptContent))
        hash := hex.EncodeToString(hasher.Sum(nil))[:12] // Use first 12 chars

        return fmt.Sprintf("golden-qemu-%s", hash), nil</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "strings"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"
        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
        "github.com/google/uuid"
)

// InstanceTags represents searchable metadata for instance VMs.
// These tags are used to track VM status and lifecycle.
type InstanceTags struct {
        Role       string // instance
        Status     string // free, connected
        CreatedAt  string
        LastUsed   string
        InstanceID string
}

// CreateInstance creates a new instance VM with proper networking setup.
// This creates only the compute instance without any volumes or QEMU setup.
// Volumes will be attached separately when users connect.
// It returns the instance ID and any error encountered.
func CreateInstance(ctx context.Context, clients *AzureClients, config *VMConfig) (string, error) <span class="cov0" title="0">{
        instanceID := uuid.New().String()
        namer := NewResourceNamer(clients.Suffix)
        vmName := namer.BoxVMName(instanceID)
        nicName := namer.BoxNICName(instanceID)
        nsgName := namer.BoxNSGName(instanceID)

        // Create NSG for the instance
        nsg, err := createInstanceNSG(ctx, clients, nsgName)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("creating instance NSG: %w", err)
        }</span>

        // Create NIC with the NSG
        <span class="cov0" title="0">nic, err := createInstanceNIC(ctx, clients, nicName, nsg.ID)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("creating instance NIC: %w", err)
        }</span>

        // Create the VM (instance only, no volumes)
        <span class="cov0" title="0">now := time.Now().UTC()
        tags := InstanceTags{
                Role:       ResourceRoleInstance,
                Status:     ResourceStatusFree,
                CreatedAt:  now.Format(time.RFC3339),
                LastUsed:   now.Format(time.RFC3339),
                InstanceID: instanceID,
        }

        _, err = createInstanceVM(ctx, clients, vmName, *nic.ID, config, tags)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("creating instance VM: %w", err)
        }</span>

        <span class="cov0" title="0">return instanceID, nil</span>
}

func createInstanceNSG(ctx context.Context, clients *AzureClients, nsgName string) (*armnetwork.SecurityGroup, error) <span class="cov0" title="0">{
        nsgParams := armnetwork.SecurityGroup{
                Location: to.Ptr(Location),
                Properties: &amp;armnetwork.SecurityGroupPropertiesFormat{
                        SecurityRules: []*armnetwork.SecurityRule{
                                {
                                        Name: to.Ptr("AllowICMPFromBastion"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolIcmp),
                                                SourceAddressPrefix:      to.Ptr(bastionSubnetCIDR),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("*"),
                                                DestinationPortRange:     to.Ptr("*"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessAllow),
                                                Priority:                 to.Ptr(int32(100)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionInbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("AllowSSHFromBastion"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolTCP),
                                                SourceAddressPrefix:      to.Ptr(bastionSubnetCIDR),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("*"),
                                                DestinationPortRange:     to.Ptr("22"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessAllow),
                                                Priority:                 to.Ptr(int32(110)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionInbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("AllowBoxSSHFromBastion"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolTCP),
                                                SourceAddressPrefix:      to.Ptr(bastionSubnetCIDR),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("*"),
                                                DestinationPortRange:     to.Ptr(fmt.Sprintf("%d", BoxSSHPort)),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessAllow),
                                                Priority:                 to.Ptr(int32(111)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionInbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("DenyAllInbound"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolAsterisk),
                                                SourceAddressPrefix:      to.Ptr("*"),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("*"),
                                                DestinationPortRange:     to.Ptr("*"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessDeny),
                                                Priority:                 to.Ptr(int32(4096)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionInbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("DenyBoxesSubnet"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolAsterisk),
                                                SourceAddressPrefix:      to.Ptr("*"),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr(boxesSubnetCIDR),
                                                DestinationPortRange:     to.Ptr("*"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessDeny),
                                                Priority:                 to.Ptr(int32(100)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionOutbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("DenyBastionSubnet"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolAsterisk),
                                                SourceAddressPrefix:      to.Ptr("*"),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr(bastionSubnetCIDR),
                                                DestinationPortRange:     to.Ptr("*"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessDeny),
                                                Priority:                 to.Ptr(int32(110)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionOutbound),
                                        },
                                },
                                {
                                        Name: to.Ptr("AllowInternetOutbound"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolAsterisk),
                                                SourceAddressPrefix:      to.Ptr("*"),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("Internet"),
                                                DestinationPortRange:     to.Ptr("*"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessAllow),
                                                Priority:                 to.Ptr(int32(4000)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionOutbound),
                                        },
                                },
                        },
                },
        }

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.NSGClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, nsgName, nsgParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting NSG creation: %w", err)
        }</span>

        <span class="cov0" title="0">nsg, err := poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating NSG: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;nsg.SecurityGroup, nil</span>
}

func createInstanceNIC(ctx context.Context, clients *AzureClients, nicName string, nsgID *string) (*armnetwork.Interface, error) <span class="cov0" title="0">{
        nicParams := armnetwork.Interface{
                Location: to.Ptr(Location),
                Properties: &amp;armnetwork.InterfacePropertiesFormat{
                        NetworkSecurityGroup: &amp;armnetwork.SecurityGroup{
                                ID: nsgID,
                        },
                        IPConfigurations: []*armnetwork.InterfaceIPConfiguration{
                                {
                                        Name: to.Ptr("ipconfig1"),
                                        Properties: &amp;armnetwork.InterfaceIPConfigurationPropertiesFormat{
                                                Subnet: &amp;armnetwork.Subnet{
                                                        ID: to.Ptr(clients.BoxesSubnetID),
                                                },
                                                PrivateIPAllocationMethod: to.Ptr(armnetwork.IPAllocationMethodDynamic),
                                        },
                                },
                        },
                },
        }

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.NICClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, nicName, nicParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting NIC creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating NIC: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;result.Interface, nil</span>
}

func createInstanceVM(ctx context.Context, clients *AzureClients, vmName string, nicID string, config *VMConfig, tags InstanceTags) (*armcompute.VirtualMachine, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        tagsMap := map[string]*string{
                TagKeyRole:     to.Ptr(tags.Role),
                TagKeyStatus:   to.Ptr(tags.Status),
                TagKeyCreated:  to.Ptr(tags.CreatedAt),
                TagKeyLastUsed: to.Ptr(tags.LastUsed),
                "instance_id":  to.Ptr(tags.InstanceID),
        }

        vmParams := armcompute.VirtualMachine{
                Location: to.Ptr(Location),
                Tags:     tagsMap,
                Properties: &amp;armcompute.VirtualMachineProperties{
                        HardwareProfile: &amp;armcompute.HardwareProfile{
                                VMSize: to.Ptr(armcompute.VirtualMachineSizeTypes(config.VMSize)),
                        },
                        StorageProfile: &amp;armcompute.StorageProfile{
                                ImageReference: &amp;armcompute.ImageReference{
                                        Publisher: to.Ptr(VMPublisher),
                                        Offer:     to.Ptr(VMOffer),
                                        SKU:       to.Ptr(VMSku),
                                        Version:   to.Ptr(VMVersion),
                                },
                                OSDisk: &amp;armcompute.OSDisk{
                                        Name:         to.Ptr(namer.BoxOSDiskName(tags.InstanceID)),
                                        CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesFromImage),
                                        ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                                                StorageAccountType: to.Ptr(armcompute.StorageAccountTypesPremiumLRS),
                                        },
                                },
                        },
                        OSProfile: &amp;armcompute.OSProfile{
                                ComputerName:  to.Ptr(namer.BoxComputerName(tags.InstanceID)),
                                AdminUsername: to.Ptr(config.AdminUsername),
                                LinuxConfiguration: &amp;armcompute.LinuxConfiguration{
                                        DisablePasswordAuthentication: to.Ptr(true),
                                        SSH: &amp;armcompute.SSHConfiguration{
                                                PublicKeys: []*armcompute.SSHPublicKey{
                                                        {
                                                                Path:    to.Ptr(fmt.Sprintf("/home/%s/.ssh/authorized_keys", config.AdminUsername)),
                                                                KeyData: to.Ptr(config.SSHPublicKey),
                                                        },
                                                },
                                        },
                                },
                        },
                        NetworkProfile: &amp;armcompute.NetworkProfile{
                                NetworkInterfaces: []*armcompute.NetworkInterfaceReference{
                                        {
                                                ID: to.Ptr(nicID),
                                        },
                                },
                        },
                },
        }

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, vmName, vmParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting VM creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating VM: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;result.VirtualMachine, nil</span>
}

// DeallocateBox deallocates a box VM.
// It stops the VM and releases compute resources while preserving the VM configuration.
func DeallocateBox(ctx context.Context, clients *AzureClients, vmID string) error <span class="cov0" title="0">{
        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.ComputeClient.BeginDeallocate(ctx, clients.ResourceGroupName, vmID, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("starting VM deallocation: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("deallocating VM: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// FindInstancesByStatus returns instance IDs matching the given status.
// It filters VMs based on their status tag and returns their resource IDs.
func FindInstancesByStatus(ctx context.Context, clients *AzureClients, status string) ([]string, error) <span class="cov0" title="0">{
        filter := fmt.Sprintf("tagName eq 'status' and tagValue eq '%s'", status)

        pager := clients.ComputeClient.NewListPager(clients.ResourceGroupName, &amp;armcompute.VirtualMachinesClientListOptions{
                Filter: &amp;filter,
        })
        var instances []string

        for pager.More() </span><span class="cov0" title="0">{
                page, err := pager.NextPage(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("listing VMs: %w", err)
                }</span>

                <span class="cov0" title="0">for _, vm := range page.Value </span><span class="cov0" title="0">{
                        if vm.Tags != nil &amp;&amp; vm.Tags[TagKeyStatus] != nil &amp;&amp; *vm.Tags[TagKeyStatus] == status </span><span class="cov0" title="0">{
                                instances = append(instances, *vm.ID)
                        }</span>
                }
        }

        <span class="cov0" title="0">return instances, nil</span>
}

// instanceResourceInfo holds information about resources associated with an instance
type instanceResourceInfo struct {
        instanceID   string
        nicID        string
        nicName      string
        nsgName      string
        osDiskName   string
        dataDiskName string
}

// DeleteInstance completely removes an instance VM and all its associated resources.
// This includes the VM, its OS disk, data disk (if any), NIC, and NSG.
// This function is used for both temporary cleanup and pool shrinking operations.
func DeleteInstance(ctx context.Context, clients *AzureClients, resourceGroupName, vmName string) error <span class="cov0" title="0">{
        // Get VM and extract resource information
        vm, err := clients.ComputeClient.Get(ctx, resourceGroupName, vmName, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Warn("VM not found, proceeding with cleanup of other resources", "vmName", vmName, "error", err)
        }</span>

        // Extract resource information from VM or generate from naming patterns
        <span class="cov0" title="0">resourceInfo := extractInstanceResourceInfo(vm, vmName, resourceGroupName, err == nil)

        slog.Info("Deleting box with resources", "vmName", vmName, "nicName", resourceInfo.nicName, "nsgName", resourceInfo.nsgName, "osDiskName", resourceInfo.osDiskName, "dataDiskName", resourceInfo.dataDiskName)

        // Delete resources in order: VM, data disk, OS disk, NIC, NSG
        deleteVM(ctx, clients, resourceGroupName, vmName, err == nil)
        deleteDisk(ctx, clients, resourceGroupName, resourceInfo.dataDiskName, "data disk")
        deleteDisk(ctx, clients, resourceGroupName, resourceInfo.osDiskName, "OS disk")
        deleteNIC(ctx, clients, resourceGroupName, resourceInfo.nicName, resourceInfo.nicID)
        deleteNSG(ctx, clients, resourceGroupName, resourceInfo.nsgName)

        slog.Info("Box deletion completed", "vmName", vmName)
        return nil</span>
}

// extractInstanceResourceInfo extracts resource information from VM or generates from naming patterns
func extractInstanceResourceInfo(vm armcompute.VirtualMachinesClientGetResponse, vmName, resourceGroupName string, vmExists bool) instanceResourceInfo <span class="cov0" title="0">{
        info := instanceResourceInfo{}

        if vmExists &amp;&amp; vm.Properties != nil </span><span class="cov0" title="0">{
                extractResourcesFromVM(&amp;info, vm)
        }</span>

        // Extract instance ID from VM name if not found in tags
        <span class="cov0" title="0">if info.instanceID == "" </span><span class="cov0" title="0">{
                info.instanceID = extractInstanceIDFromVMName(vmName)
        }</span>

        // Generate missing resource names using naming patterns
        <span class="cov0" title="0">generateMissingResourceNames(&amp;info, resourceGroupName)

        return info</span>
}

// extractResourcesFromVM extracts resource information from VM properties
func extractResourcesFromVM(info *instanceResourceInfo, vm armcompute.VirtualMachinesClientGetResponse) <span class="cov0" title="0">{
        // Extract instance ID from tags
        if vm.Tags != nil &amp;&amp; vm.Tags["instance_id"] != nil </span><span class="cov0" title="0">{
                info.instanceID = *vm.Tags["instance_id"]
        }</span>

        // Get NIC ID
        <span class="cov0" title="0">if vm.Properties.NetworkProfile != nil &amp;&amp; len(vm.Properties.NetworkProfile.NetworkInterfaces) &gt; 0 </span><span class="cov0" title="0">{
                info.nicID = *vm.Properties.NetworkProfile.NetworkInterfaces[0].ID
        }</span>

        // Get disk names from storage profile
        <span class="cov0" title="0">if vm.Properties.StorageProfile != nil </span><span class="cov0" title="0">{
                if vm.Properties.StorageProfile.OSDisk != nil </span><span class="cov0" title="0">{
                        info.osDiskName = *vm.Properties.StorageProfile.OSDisk.Name
                }</span>
                <span class="cov0" title="0">if len(vm.Properties.StorageProfile.DataDisks) &gt; 0 </span><span class="cov0" title="0">{
                        info.dataDiskName = *vm.Properties.StorageProfile.DataDisks[0].Name
                }</span>
        }
}

// extractInstanceIDFromVMName extracts instance ID from VM name using naming pattern
func extractInstanceIDFromVMName(vmName string) string <span class="cov0" title="0">{
        parts := strings.Split(vmName, "-")
        if len(parts) &gt;= 4 </span><span class="cov0" title="0">{
                return parts[len(parts)-2]
        }</span>
        <span class="cov0" title="0">return ""</span>
}

// generateMissingResourceNames generates missing resource names using naming patterns
func generateMissingResourceNames(info *instanceResourceInfo, resourceGroupName string) <span class="cov0" title="0">{
        if info.instanceID == "" </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">namer := NewResourceNamer(extractSuffix(resourceGroupName))
        info.nicName = namer.BoxNICName(info.instanceID)
        info.nsgName = namer.BoxNSGName(info.instanceID)

        if info.osDiskName == "" </span><span class="cov0" title="0">{
                info.osDiskName = namer.BoxOSDiskName(info.instanceID)
        }</span>
        <span class="cov0" title="0">if info.dataDiskName == "" </span><span class="cov0" title="0">{
                info.dataDiskName = namer.BoxDataDiskName(info.instanceID)
        }</span>
}

// deleteVM deletes a virtual machine
func deleteVM(ctx context.Context, clients *AzureClients, resourceGroupName, vmName string, vmExists bool) <span class="cov0" title="0">{
        if !vmExists </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Deleting VM", "vmName", vmName)
        vmDelete, err := clients.ComputeClient.BeginDelete(ctx, resourceGroupName, vmName, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to start VM deletion", "vmName", vmName, "error", err)
                return
        }</span>

        <span class="cov0" title="0">_, err = vmDelete.PollUntilDone(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed waiting for VM deletion", "vmName", vmName, "error", err)
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Successfully deleted VM", "vmName", vmName)
        }</span>
}

// deleteDisk deletes a disk (OS or data disk)
func deleteDisk(ctx context.Context, clients *AzureClients, resourceGroupName, diskName, diskType string) <span class="cov0" title="0">{
        if diskName == "" </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Deleting disk", "diskType", diskType, "diskName", diskName)
        diskDelete, err := clients.DisksClient.BeginDelete(ctx, resourceGroupName, diskName, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to start disk deletion", "diskType", diskType, "diskName", diskName, "error", err)
                return
        }</span>

        <span class="cov0" title="0">_, err = diskDelete.PollUntilDone(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed waiting for disk deletion", "diskType", diskType, "diskName", diskName, "error", err)
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Successfully deleted disk", "diskType", diskType, "diskName", diskName)
        }</span>
}

// deleteNIC deletes a network interface
func deleteNIC(ctx context.Context, clients *AzureClients, resourceGroupName, nicName, nicID string) <span class="cov0" title="0">{
        targetNICName := nicName
        if targetNICName == "" &amp;&amp; nicID != "" </span><span class="cov0" title="0">{
                parts := strings.Split(nicID, "/")
                targetNICName = parts[len(parts)-1]
        }</span>

        <span class="cov0" title="0">if targetNICName == "" </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Deleting NIC", "nicName", targetNICName)
        nicDelete, err := clients.NICClient.BeginDelete(ctx, resourceGroupName, targetNICName, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to start NIC deletion", "nicName", targetNICName, "error", err)
                return
        }</span>

        <span class="cov0" title="0">_, err = nicDelete.PollUntilDone(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed waiting for NIC deletion", "nicName", targetNICName, "error", err)
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Successfully deleted NIC", "nicName", targetNICName)
        }</span>
}

// deleteNSG deletes a network security group
func deleteNSG(ctx context.Context, clients *AzureClients, resourceGroupName, nsgName string) <span class="cov0" title="0">{
        if nsgName == "" </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Deleting NSG", "nsgName", nsgName)
        nsgDelete, err := clients.NSGClient.BeginDelete(ctx, resourceGroupName, nsgName, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to start NSG deletion", "nsgName", nsgName, "error", err)
                return
        }</span>

        <span class="cov0" title="0">_, err = nsgDelete.PollUntilDone(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed waiting for NSG deletion", "nsgName", nsgName, "error", err)
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Successfully deleted NSG", "nsgName", nsgName)
        }</span>
}

// UpdateInstanceStatus updates the status tag of an instance
func UpdateInstanceStatus(ctx context.Context, clients *AzureClients, instanceID, status string) error <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        vmName := namer.BoxVMName(instanceID)

        // Get current VM
        vm, err := clients.ComputeClient.Get(ctx, clients.ResourceGroupName, vmName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get VM for status update: %w", err)
        }</span>

        // Update status tag
        <span class="cov0" title="0">if vm.Tags == nil </span><span class="cov0" title="0">{
                vm.Tags = make(map[string]*string)
        }</span>
        <span class="cov0" title="0">vm.Tags[TagKeyStatus] = to.Ptr(status)
        vm.Tags[TagKeyLastUsed] = to.Ptr(time.Now().UTC().Format(time.RFC3339))

        // Update the VM
        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, vmName, vm.VirtualMachine, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start VM status update: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to update VM status: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// GetInstancePrivateIP retrieves the private IP address of an instance
func GetInstancePrivateIP(ctx context.Context, clients *AzureClients, instanceID string) (string, error) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        nicName := namer.BoxNICName(instanceID)

        nic, err := clients.NICClient.Get(ctx, clients.ResourceGroupName, nicName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to get NIC for instance %s: %w", instanceID, err)
        }</span>

        <span class="cov0" title="0">if len(nic.Properties.IPConfigurations) == 0 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("no IP configurations found for instance %s", instanceID)
        }</span>

        <span class="cov0" title="0">privateIP := nic.Properties.IPConfigurations[0].Properties.PrivateIPAddress
        if privateIP == nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("no private IP found for instance %s", instanceID)
        }</span>

        <span class="cov0" title="0">return *privateIP, nil</span>
}

// AttachVolumeToInstance attaches a volume to an instance VM as a data disk
func AttachVolumeToInstance(ctx context.Context, clients *AzureClients, instanceID, volumeID string) error <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        vmName := namer.BoxVMName(instanceID)
        volumeName := namer.VolumePoolDiskName(volumeID)

        // Get current VM
        vm, err := clients.ComputeClient.Get(ctx, clients.ResourceGroupName, vmName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get VM for volume attachment: %w", err)
        }</span>

        // Get volume resource ID
        <span class="cov0" title="0">volume, err := clients.DisksClient.Get(ctx, clients.ResourceGroupName, volumeName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get volume for attachment: %w", err)
        }</span>

        // Add data disk to VM
        <span class="cov0" title="0">dataDisk := &amp;armcompute.DataDisk{
                Name:         to.Ptr(volumeName),
                CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesAttach),
                Lun:          to.Ptr[int32](0),
                ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                        ID: volume.ID,
                },
        }

        if vm.Properties.StorageProfile.DataDisks == nil </span><span class="cov0" title="0">{
                vm.Properties.StorageProfile.DataDisks = []*armcompute.DataDisk{}
        }</span>
        <span class="cov0" title="0">vm.Properties.StorageProfile.DataDisks = append(vm.Properties.StorageProfile.DataDisks, dataDisk)

        // Update the VM
        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, vmName, vm.VirtualMachine, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start volume attachment: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to attach volume: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">package infra

import (
        "log/slog"
        "os"
)

// NewLogger creates a standardized JSON logger for the application
func NewLogger() *slog.Logger <span class="cov8" title="1">{
        level := slog.LevelInfo
        if os.Getenv("DEBUG") == "true" </span><span class="cov0" title="0">{
                level = slog.LevelDebug
        }</span>
        <span class="cov8" title="1">return slog.New(slog.NewJSONHandler(os.Stdout, &amp;slog.HandlerOptions{
                Level: level,
        }))</span>
}

// SetDefaultLogger configures the default slog logger to use JSON format
func SetDefaultLogger() <span class="cov8" title="1">{
        slog.SetDefault(NewLogger())
}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "os"
        "sync"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore"
        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/data/aztables"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/authorization/armauthorization"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resourcegraph/armresourcegraph"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armresources"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/storage/armstorage"
)

// VMConfig holds common VM configuration fields
type VMConfig struct {
        AdminUsername string
        SSHPublicKey  string
        VMSize        string
}

// AzureClients holds all the Azure SDK clients needed for the application
type AzureClients struct {
        Cred                         azcore.TokenCredential
        SubscriptionID               string
        Suffix                       string
        ResourceGroupSuffix          string
        ResourceGroupName            string
        BastionSubnetID              string
        BoxesSubnetID                string
        TableStorageConnectionString string
        ResourceClient               *armresources.ResourceGroupsClient
        NetworkClient                *armnetwork.VirtualNetworksClient
        NSGClient                    *armnetwork.SecurityGroupsClient
        SubnetsClient                *armnetwork.SubnetsClient
        ComputeClient                *armcompute.VirtualMachinesClient
        PublicIPClient               *armnetwork.PublicIPAddressesClient
        NICClient                    *armnetwork.InterfacesClient
        StorageClient                *armstorage.AccountsClient
        RoleClient                   *armauthorization.RoleAssignmentsClient
        TableClient                  *aztables.ServiceClient
        DisksClient                  *armcompute.DisksClient
        SnapshotsClient              *armcompute.SnapshotsClient
        ResourceGraphClient          *armresourcegraph.Client
}

func createResourceGroup(ctx context.Context, clients *AzureClients) <span class="cov0" title="0">{
        hash, err := GenerateConfigHash(clients.Suffix)
        FatalOnError(err, "failed to generate config hash")

        _, err = clients.ResourceClient.CreateOrUpdate(ctx, clients.ResourceGroupName, armresources.ResourceGroup{
                Location: to.Ptr(Location),
                Tags: map[string]*string{
                        "config": to.Ptr(fmt.Sprintf("sha256-%s", hash)),
                },
        }, nil)
        FatalOnError(err, "failed to create resource group")
}</span>

func createBastionNSG(ctx context.Context, clients *AzureClients) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        nsgParams := armnetwork.SecurityGroup{
                Location: to.Ptr(Location),
                Properties: &amp;armnetwork.SecurityGroupPropertiesFormat{
                        SecurityRules: BastionNSGRules,
                },
        }

        poller, err := clients.NSGClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, namer.BastionNSGName(), nsgParams, nil)
        FatalOnError(err, "failed to start bastion NSG creation")

        _, err = poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        FatalOnError(err, "failed to complete bastion NSG creation")
}</span>

func createVirtualNetwork(ctx context.Context, clients *AzureClients) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        nsg, err := clients.NSGClient.Get(ctx, clients.ResourceGroupName, namer.BastionNSGName(), nil)
        FatalOnError(err, "failed to get bastion NSG")

        vnetParams := armnetwork.VirtualNetwork{
                Location: to.Ptr(Location),
                Properties: &amp;armnetwork.VirtualNetworkPropertiesFormat{
                        AddressSpace: &amp;armnetwork.AddressSpace{
                                AddressPrefixes: []*string{to.Ptr(vnetAddressSpace)},
                        },
                        Subnets: []*armnetwork.Subnet{
                                {
                                        Name: to.Ptr(namer.BastionSubnetName()),
                                        Properties: &amp;armnetwork.SubnetPropertiesFormat{
                                                AddressPrefix: to.Ptr(bastionSubnetCIDR),
                                                NetworkSecurityGroup: &amp;armnetwork.SecurityGroup{
                                                        ID: nsg.ID,
                                                },
                                        },
                                },
                                {
                                        Name: to.Ptr(namer.BoxesSubnetName()),
                                        Properties: &amp;armnetwork.SubnetPropertiesFormat{
                                                AddressPrefix: to.Ptr(boxesSubnetCIDR),
                                        },
                                },
                        },
                },
        }

        poller, err := clients.NetworkClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, namer.VNetName(), vnetParams, nil)
        FatalOnError(err, "failed to start virtual network creation")

        vnetResult, err := poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        FatalOnError(err, "failed to complete virtual network creation")

        setSubnetIDsFromVNet(clients, vnetResult)
}</span>

func setSubnetIDsFromVNet(clients *AzureClients, vnetResult armnetwork.VirtualNetworksClientCreateOrUpdateResponse) <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        for _, subnet := range vnetResult.VirtualNetwork.Properties.Subnets </span><span class="cov0" title="0">{
                switch *subnet.Name </span>{
                case namer.BastionSubnetName():<span class="cov0" title="0">
                        clients.BastionSubnetID = *subnet.ID</span>
                case namer.BoxesSubnetName():<span class="cov0" title="0">
                        clients.BoxesSubnetID = *subnet.ID</span>
                }
        }

        <span class="cov0" title="0">if clients.BastionSubnetID == "" || clients.BoxesSubnetID == "" </span><span class="cov0" title="0">{
                slog.Error("missing subnets in VNet")
                os.Exit(1)
        }</span>
}

// InitializeTableStorage sets up Table Storage resources or reads configuration
func InitializeTableStorage(clients *AzureClients, useAzureCli bool) <span class="cov0" title="0">{
        if useAzureCli </span><span class="cov0" title="0">{
                namer := NewResourceNamer(clients.Suffix)
                storageAccount := namer.SharedStorageAccountName()
                tableNames := []string{namer.EventLogTableName(), namer.ResourceRegistryTableName()}

                result := CreateTableStorageResources(
                        context.Background(),
                        clients,
                        storageAccount,
                        tableNames,
                )
                FatalOnError(result.Error, "Table Storage setup error")

                clients.TableStorageConnectionString = result.ConnectionString
        }</span> else<span class="cov0" title="0"> {
                err := readTableStorageConfig(clients)
                FatalOnError(err, "Failed to read Table Storage config")
        }</span>

        // Create table client from connection string
        <span class="cov0" title="0">createTableClient(clients)</span>
}

func CreateNetworkInfrastructure(ctx context.Context, clients *AzureClients, useAzureCli bool) <span class="cov0" title="0">{
        // 1. Create resource group first and wait for it to be ready
        createResourceGroup(ctx, clients)

        // Start Table Storage initialization in parallel with NSG and VNet creation
        var wg sync.WaitGroup
        wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer wg.Done()
                // Initialize Table Storage after resource group is created
                InitializeTableStorage(clients, useAzureCli)
        }</span>()

        // 2. Create NSG first since VNet depends on it
        <span class="cov0" title="0">createBastionNSG(ctx, clients)

        // 3. Create VNet after NSG is ready
        createVirtualNetwork(ctx, clients)

        // Wait for Table Storage initialization to complete
        wg.Wait()</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "sync"
        "time"

        "github.com/google/uuid"
)

// PoolConfig holds configuration for dual pool management (instances + volumes)
type PoolConfig struct {
        // Instance pool settings
        MinFreeInstances  int
        MaxFreeInstances  int
        MaxTotalInstances int

        // Volume pool settings
        MinFreeVolumes  int
        MaxFreeVolumes  int
        MaxTotalVolumes int

        // Timing settings
        CheckInterval     time.Duration
        ScaleDownCooldown time.Duration
}

// NewDefaultPoolConfig creates a production pool configuration
func NewDefaultPoolConfig() PoolConfig <span class="cov0" title="0">{
        return PoolConfig{
                MinFreeInstances:  DefaultMinFreeInstances,
                MaxFreeInstances:  DefaultMaxFreeInstances,
                MaxTotalInstances: DefaultMaxTotalInstances,
                MinFreeVolumes:    DefaultMinFreeVolumes,
                MaxFreeVolumes:    DefaultMaxFreeVolumes,
                MaxTotalVolumes:   DefaultMaxTotalVolumes,
                CheckInterval:     DefaultCheckInterval,
                ScaleDownCooldown: DefaultScaleDownCooldown,
        }
}</span>

// NewDevPoolConfig creates a development pool configuration
func NewDevPoolConfig() PoolConfig <span class="cov0" title="0">{
        return PoolConfig{
                MinFreeInstances:  DevMinFreeInstances,
                MaxFreeInstances:  DevMaxFreeInstances,
                MaxTotalInstances: DevMaxTotalInstances,
                MinFreeVolumes:    DevMinFreeVolumes,
                MaxFreeVolumes:    DevMaxFreeVolumes,
                MaxTotalVolumes:   DevMaxTotalVolumes,
                CheckInterval:     DevCheckInterval,
                ScaleDownCooldown: DevScaleDownCooldown,
        }
}</span>

type BoxPool struct {
        mu              sync.RWMutex
        clients         *AzureClients
        vmConfig        *VMConfig
        poolConfig      PoolConfig
        resourceQueries *ResourceGraphQueries
        goldenSnapshot  *GoldenSnapshotInfo
        lastScaleDown   time.Time // Track last scale down to enforce cooldown
}

func NewBoxPool(clients *AzureClients, vmConfig *VMConfig, poolConfig PoolConfig, goldenSnapshot *GoldenSnapshotInfo) *BoxPool <span class="cov0" title="0">{
        resourceQueries := NewResourceGraphQueries(
                clients.ResourceGraphClient,
                clients.SubscriptionID,
                clients.ResourceGroupName,
        )

        return &amp;BoxPool{
                clients:         clients,
                vmConfig:        vmConfig,
                poolConfig:      poolConfig,
                resourceQueries: resourceQueries,
                goldenSnapshot:  goldenSnapshot,
        }
}</span>

func (p *BoxPool) MaintainPool(ctx context.Context) <span class="cov0" title="0">{
        ticker := time.NewTicker(p.poolConfig.CheckInterval)
        defer ticker.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        // Maintain both instance and volume pools
                        p.maintainInstancePool(ctx)
                        p.maintainVolumePool(ctx)</span>
                }
        }
}

func (p *BoxPool) maintainInstancePool(ctx context.Context) <span class="cov0" title="0">{
        counts, err := p.resourceQueries.CountInstancesByStatus(ctx)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to get instance counts", "error", err)
                return
        }</span>

        <span class="cov0" title="0">slog.Debug("instance pool status",
                "free", counts.Free,
                "connected", counts.Connected,
                "total", counts.Total)

        if counts.Free &lt; p.poolConfig.MinFreeInstances </span><span class="cov0" title="0">{
                p.scaleUpInstances(ctx, counts.Free)
        }</span> else<span class="cov0" title="0"> if counts.Free &gt; p.poolConfig.MaxFreeInstances </span><span class="cov0" title="0">{
                p.scaleDownInstances(ctx, counts.Free)
        }</span>
}

func (p *BoxPool) maintainVolumePool(ctx context.Context) <span class="cov0" title="0">{
        counts, err := p.resourceQueries.CountVolumesByStatus(ctx)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to get volume counts", "error", err)
                return
        }</span>

        <span class="cov0" title="0">slog.Debug("volume pool status",
                "free", counts.Free,
                "attached", counts.Attached,
                "total", counts.Total)

        if counts.Free &lt; p.poolConfig.MinFreeVolumes </span><span class="cov0" title="0">{
                p.scaleUpVolumes(ctx, counts.Free)
        }</span> else<span class="cov0" title="0"> if counts.Free &gt; p.poolConfig.MaxFreeVolumes </span><span class="cov0" title="0">{
                p.scaleDownVolumes(ctx, counts.Free)
        }</span>
}

func (p *BoxPool) scaleUpInstances(ctx context.Context, currentSize int) <span class="cov0" title="0">{
        instancesToCreate := max(0, p.poolConfig.MinFreeInstances-currentSize)
        slog.Info("creating instances to maintain pool size", "count", instancesToCreate)

        var wg sync.WaitGroup
        for i := 0; i &lt; instancesToCreate; i++ </span><span class="cov0" title="0">{
                wg.Add(1)
                go func() </span><span class="cov0" title="0">{
                        defer wg.Done()
                        instanceID, err := CreateInstance(ctx, p.clients, p.vmConfig)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to create instance", "error", err)
                                return
                        }</span>

                        <span class="cov0" title="0">slog.Info("created instance", "instanceID", instanceID)

                        // Log instance creation event
                        now := time.Now()
                        createEvent := EventLogEntity{
                                PartitionKey: now.Format("2006-01-02"),
                                RowKey:       fmt.Sprintf("%s_instance_create", now.Format("20060102T150405")),
                                Timestamp:    now,
                                EventType:    "instance_create",
                                BoxID:        instanceID,
                                Details:      fmt.Sprintf(`{"status":"%s"}`, ResourceStatusFree),
                        }
                        if err := WriteEventLog(ctx, p.clients, createEvent); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log instance create event", "error", err)
                        }</span>

                        // Log resource registry entry
                        <span class="cov0" title="0">resourceEntry := ResourceRegistryEntity{
                                PartitionKey: ResourceRoleInstance,
                                RowKey:       instanceID,
                                Timestamp:    now,
                                Status:       ResourceStatusFree,
                                CreatedAt:    now,
                                LastActivity: now,
                                Metadata:     fmt.Sprintf(`{"vm_size":"%s"}`, p.vmConfig.VMSize),
                        }
                        if err := WriteResourceRegistry(ctx, p.clients, resourceEntry); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log resource registry entry", "error", err)
                        }</span>
                }()
        }
        <span class="cov0" title="0">wg.Wait()</span>
}

func (p *BoxPool) scaleDownInstances(ctx context.Context, currentSize int) <span class="cov0" title="0">{
        // Check if enough time has passed since last scale down
        p.mu.Lock()
        if time.Since(p.lastScaleDown) &lt; p.poolConfig.ScaleDownCooldown </span><span class="cov0" title="0">{
                p.mu.Unlock()
                slog.Info("skipping instance scale down due to cooldown",
                        "time_remaining", p.poolConfig.ScaleDownCooldown-time.Since(p.lastScaleDown))
                return
        }</span>
        <span class="cov0" title="0">p.mu.Unlock()

        instancesToRemove := currentSize - p.poolConfig.MaxFreeInstances
        slog.Info("removing excess instances from pool", "count", instancesToRemove)

        // Get oldest free instances to remove
        oldestInstances, err := p.resourceQueries.GetOldestFreeInstances(ctx, instancesToRemove)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to get oldest free instances", "error", err)
                return
        }</span>

        // Delete instances
        <span class="cov0" title="0">var wg sync.WaitGroup
        for _, instance := range oldestInstances </span><span class="cov0" title="0">{
                wg.Add(1)
                go func(inst ResourceInfo) </span><span class="cov0" title="0">{
                        defer wg.Done()
                        namer := NewResourceNamer(p.clients.Suffix)
                        vmName := namer.BoxVMName(inst.ResourceID)
                        resourceGroup := namer.ResourceGroup()

                        err := DeleteInstance(ctx, p.clients, resourceGroup, vmName)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to delete instance", "instanceID", inst.ResourceID, "error", err)
                                return
                        }</span>

                        <span class="cov0" title="0">slog.Info("deleted instance", "instanceID", inst.ResourceID)

                        // Log instance deletion event
                        now := time.Now()
                        deleteEvent := EventLogEntity{
                                PartitionKey: now.Format("2006-01-02"),
                                RowKey:       fmt.Sprintf("%s_instance_delete", now.Format("20060102T150405")),
                                Timestamp:    now,
                                EventType:    "instance_delete",
                                BoxID:        inst.ResourceID,
                                Details:      `{"reason":"pool_shrink"}`,
                        }
                        if err := WriteEventLog(ctx, p.clients, deleteEvent); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log instance delete event", "error", err)
                        }</span>
                }(instance)
        }
        <span class="cov0" title="0">wg.Wait()

        // Update last scale down time
        p.mu.Lock()
        p.lastScaleDown = time.Now()
        p.mu.Unlock()</span>
}

func (p *BoxPool) scaleUpVolumes(ctx context.Context, currentSize int) <span class="cov0" title="0">{
        volumesToCreate := max(0, p.poolConfig.MinFreeVolumes-currentSize)
        slog.Info("creating volumes to maintain pool size", "count", volumesToCreate)

        var wg sync.WaitGroup
        for i := 0; i &lt; volumesToCreate; i++ </span><span class="cov0" title="0">{
                wg.Add(1)
                go func() </span><span class="cov0" title="0">{
                        defer wg.Done()

                        namer := NewResourceNamer(p.clients.Suffix)
                        volumeID := uuid.New().String()
                        volumeName := namer.VolumePoolDiskName(volumeID)

                        now := time.Now().UTC()
                        tags := VolumeTags{
                                Role:      ResourceRoleVolume,
                                Status:    ResourceStatusFree,
                                CreatedAt: now.Format(time.RFC3339),
                                LastUsed:  now.Format(time.RFC3339),
                                VolumeID:  volumeID,
                        }

                        _, err := CreateVolumeFromSnapshot(ctx, p.clients, p.clients.ResourceGroupName,
                                volumeName, p.goldenSnapshot.ResourceID, tags)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to create volume from golden snapshot", "error", err)
                                return
                        }</span>

                        <span class="cov0" title="0">slog.Info("created volume from golden snapshot", "volumeID", volumeID)

                        // Log volume creation event
                        createEvent := EventLogEntity{
                                PartitionKey: now.Format("2006-01-02"),
                                RowKey:       fmt.Sprintf("%s_volume_create_%s", now.Format("20060102T150405.000"), volumeID),
                                Timestamp:    now,
                                EventType:    "volume_create",
                                BoxID:        volumeID,
                                Details:      fmt.Sprintf(`{"status":"%s","size_gb":%d}`, ResourceStatusFree, DefaultVolumeSizeGB),
                        }
                        if err := WriteEventLog(ctx, p.clients, createEvent); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log volume create event", "error", err)
                        }</span>

                        // Log resource registry entry
                        <span class="cov0" title="0">resourceEntry := ResourceRegistryEntity{
                                PartitionKey: ResourceRoleVolume,
                                RowKey:       volumeID,
                                Timestamp:    now,
                                Status:       ResourceStatusFree,
                                CreatedAt:    now,
                                LastActivity: now,
                                Metadata:     fmt.Sprintf(`{"size_gb":%d}`, DefaultVolumeSizeGB),
                        }
                        if err := WriteResourceRegistry(ctx, p.clients, resourceEntry); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log resource registry entry", "error", err)
                        }</span>
                }()
        }
        <span class="cov0" title="0">wg.Wait()</span>
}

func (p *BoxPool) scaleDownVolumes(ctx context.Context, currentSize int) <span class="cov0" title="0">{
        // Check if enough time has passed since last scale down
        p.mu.Lock()
        if time.Since(p.lastScaleDown) &lt; p.poolConfig.ScaleDownCooldown </span><span class="cov0" title="0">{
                p.mu.Unlock()
                slog.Info("skipping volume scale down due to cooldown",
                        "time_remaining", p.poolConfig.ScaleDownCooldown-time.Since(p.lastScaleDown))
                return
        }</span>
        <span class="cov0" title="0">p.mu.Unlock()

        volumesToRemove := currentSize - p.poolConfig.MaxFreeVolumes
        slog.Info("removing excess volumes from pool", "count", volumesToRemove)

        // Get oldest free volumes to remove
        oldestVolumes, err := p.resourceQueries.GetOldestFreeVolumes(ctx, volumesToRemove)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to get oldest free volumes", "error", err)
                return
        }</span>

        // Delete volumes
        <span class="cov0" title="0">var wg sync.WaitGroup
        for _, volume := range oldestVolumes </span><span class="cov0" title="0">{
                wg.Add(1)
                go func(vol ResourceInfo) </span><span class="cov0" title="0">{
                        defer wg.Done()

                        err := DeleteVolume(ctx, p.clients, p.clients.ResourceGroupName, vol.Name)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to delete volume", "volumeID", vol.ResourceID, "error", err)
                                return
                        }</span>

                        <span class="cov0" title="0">slog.Info("deleted volume", "volumeID", vol.ResourceID)

                        // Log volume deletion event
                        now := time.Now()
                        deleteEvent := EventLogEntity{
                                PartitionKey: now.Format("2006-01-02"),
                                RowKey:       fmt.Sprintf("%s_volume_delete", now.Format("20060102T150405")),
                                Timestamp:    now,
                                EventType:    "volume_delete",
                                BoxID:        vol.ResourceID,
                                Details:      `{"reason":"pool_shrink"}`,
                        }
                        if err := WriteEventLog(ctx, p.clients, deleteEvent); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to log volume delete event", "error", err)
                        }</span>
                }(volume)
        }
        <span class="cov0" title="0">wg.Wait()

        // Update last scale down time
        p.mu.Lock()
        p.lastScaleDown = time.Now()
        p.mu.Unlock()</span>
}
</pre>
		
		<pre class="file" id="file8" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "time"

        "shellbox/internal/sshutil"
)

// QEMUManager handles QEMU VM operations on instances
type QEMUManager struct {
        clients *AzureClients
}

// NewQEMUManager creates a new QEMU manager
func NewQEMUManager(clients *AzureClients) *QEMUManager <span class="cov0" title="0">{
        return &amp;QEMUManager{
                clients: clients,
        }
}</span>

// StartQEMUWithVolume starts QEMU VM with the attached volume
func (qm *QEMUManager) StartQEMUWithVolume(ctx context.Context, instanceIP, _ string) error <span class="cov0" title="0">{
        // Wait for volume to be available and then resume QEMU
        resumeCmd := `
# Wait for data disk to be available
while [ ! -e /dev/disk/azure/scsi1/lun0 ]; do
    echo "Waiting for data disk..."
    sleep 2
done

# Mount data disk if not already mounted
if ! mountpoint -q /mnt/userdata; then
    sudo mkdir -p /mnt/userdata
    sudo mount /dev/disk/azure/scsi1/lun0 /mnt/userdata
fi

# Change to working directory
cd /mnt/userdata

# Resume QEMU VM from saved state
sudo qemu-system-x86_64 \
   -enable-kvm \
   -m 24G \
   -mem-prealloc \
   -mem-path /mnt/userdata/qemu-memory/ubuntu-mem \
   -smp 8 \
   -cpu host \
   -drive file=/mnt/userdata/qemu-disks/ubuntu-base.qcow2,format=qcow2 \
   -drive file=/mnt/userdata/qemu-disks/cloud-init.iso,format=raw \
   -nographic \
   -monitor unix:/tmp/qemu-monitor.sock,server,nowait \
   -nic user,model=virtio,hostfwd=tcp::2222-:22,dns=8.8.8.8 \
   -loadvm ssh-ready &amp;

# Wait for QEMU to be ready
echo "Waiting for QEMU to resume..."
sleep 10
`

        if err := sshutil.ExecuteCommand(ctx, resumeCmd, AdminUsername, instanceIP); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start QEMU: %w", err)
        }</span>

        // Wait for QEMU SSH to be ready
        <span class="cov0" title="0">if err := qm.waitForQEMUSSH(ctx, instanceIP); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("QEMU SSH not ready: %w", err)
        }</span>

        <span class="cov0" title="0">slog.Info("QEMU started", "instance_ip", instanceIP)
        return nil</span>
}

// StopQEMU stops the QEMU VM and saves its state
func (qm *QEMUManager) StopQEMU(ctx context.Context, instanceIP string) error <span class="cov0" title="0">{
        stopCmd := `
# Save QEMU state and quit
echo -e "savevm ssh-ready\nquit" | sudo socat - UNIX-CONNECT:/tmp/qemu-monitor.sock || true

# Fallback: kill QEMU if monitor command fails
sudo pkill qemu-system-x86_64 || true
`

        if err := sshutil.ExecuteCommand(ctx, stopCmd, AdminUsername, instanceIP); err != nil </span><span class="cov0" title="0">{
                slog.Warn("Error stopping QEMU (expected during shutdown)", "instance_ip", instanceIP, "error", err)
                // Don't return error - stopping QEMU often causes connection issues
        }</span>

        <span class="cov0" title="0">slog.Info("QEMU stopped", "instance_ip", instanceIP)
        return nil</span>
}

// waitForQEMUSSH waits for QEMU VM to be SSH-accessible
func (qm *QEMUManager) waitForQEMUSSH(ctx context.Context, instanceIP string) error <span class="cov0" title="0">{
        return RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                testCmd := fmt.Sprintf(`
timeout 5 ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -p %d ubuntu@localhost 'echo QEMU SSH ready' || exit 1
`, BoxSSHPort)

                return sshutil.ExecuteCommand(ctx, testCmd, AdminUsername, instanceIP)
        }</span>, 2*time.Minute, 10*time.Second, "QEMU SSH connectivity")
}
</pre>
		
		<pre class="file" id="file9" style="display: none">package infra

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
)

// AllocatedResources represents resources allocated to a user session
type AllocatedResources struct {
        InstanceID string
        VolumeID   string
        InstanceIP string
}

// ResourceAllocator manages dynamic allocation of instances and volumes
type ResourceAllocator struct {
        clients         *AzureClients
        resourceQueries *ResourceGraphQueries
        qemuManager     *QEMUManager
}

// NewResourceAllocator creates a new resource allocator
func NewResourceAllocator(clients *AzureClients, resourceQueries *ResourceGraphQueries) *ResourceAllocator <span class="cov0" title="0">{
        return &amp;ResourceAllocator{
                clients:         clients,
                resourceQueries: resourceQueries,
                qemuManager:     NewQEMUManager(clients),
        }
}</span>

// AllocateResourcesForUser finds and allocates a free instance and volume for a user
func (ra *ResourceAllocator) AllocateResourcesForUser(ctx context.Context, userID string) (*AllocatedResources, error) <span class="cov0" title="0">{
        // Find available resources
        instance, volume, err := ra.findAvailableResources(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Perform allocation steps with rollback on failure
        <span class="cov0" title="0">if err := ra.performAllocation(ctx, instance, volume); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        // Get instance IP and start QEMU
        <span class="cov0" title="0">instanceIP, err := ra.finalizeAllocation(ctx, instance, volume)
        if err != nil </span><span class="cov0" title="0">{
                ra.rollbackAllocation(ctx, instance.ResourceID, volume.ResourceID)
                return nil, err
        }</span>

        <span class="cov0" title="0">slog.Info("resources allocated", "instance_id", instance.ResourceID, "volume_id", volume.ResourceID, "user_id", userID)

        return &amp;AllocatedResources{
                InstanceID: instance.ResourceID,
                VolumeID:   volume.ResourceID,
                InstanceIP: instanceIP,
        }, nil</span>
}

// findAvailableResources queries for available instances and volumes
func (ra *ResourceAllocator) findAvailableResources(ctx context.Context) (ResourceInfo, ResourceInfo, error) <span class="cov0" title="0">{
        // Get free instances
        freeInstances, err := ra.resourceQueries.GetInstancesByStatus(ctx, ResourceStatusFree)
        if err != nil </span><span class="cov0" title="0">{
                return ResourceInfo{}, ResourceInfo{}, fmt.Errorf("failed to query free instances: %w", err)
        }</span>
        <span class="cov0" title="0">if len(freeInstances) == 0 </span><span class="cov0" title="0">{
                return ResourceInfo{}, ResourceInfo{}, fmt.Errorf("no free instances available")
        }</span>

        // Get free volumes
        <span class="cov0" title="0">freeVolumes, err := ra.resourceQueries.GetVolumesByStatus(ctx, ResourceStatusFree)
        if err != nil </span><span class="cov0" title="0">{
                return ResourceInfo{}, ResourceInfo{}, fmt.Errorf("failed to query free volumes: %w", err)
        }</span>
        <span class="cov0" title="0">if len(freeVolumes) == 0 </span><span class="cov0" title="0">{
                return ResourceInfo{}, ResourceInfo{}, fmt.Errorf("no free volumes available")
        }</span>

        <span class="cov0" title="0">return freeInstances[0], freeVolumes[0], nil</span>
}

// performAllocation marks resources as allocated and attaches volume
func (ra *ResourceAllocator) performAllocation(ctx context.Context, instance, volume ResourceInfo) error <span class="cov0" title="0">{
        // Mark instance as connected
        if err := UpdateInstanceStatus(ctx, ra.clients, instance.ResourceID, ResourceStatusConnected); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to mark instance as connected: %w", err)
        }</span>

        // Mark volume as attached
        <span class="cov0" title="0">if err := UpdateVolumeStatus(ctx, ra.clients, volume.ResourceID, ResourceStatusAttached); err != nil </span><span class="cov0" title="0">{
                ra.rollbackInstanceStatus(ctx, instance.ResourceID)
                return fmt.Errorf("failed to mark volume as attached: %w", err)
        }</span>

        // Attach volume to instance
        <span class="cov0" title="0">if err := AttachVolumeToInstance(ctx, ra.clients, instance.ResourceID, volume.ResourceID); err != nil </span><span class="cov0" title="0">{
                ra.rollbackAllocation(ctx, instance.ResourceID, volume.ResourceID)
                return fmt.Errorf("failed to attach volume to instance: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// finalizeAllocation gets IP and starts QEMU
func (ra *ResourceAllocator) finalizeAllocation(ctx context.Context, instance, volume ResourceInfo) (string, error) <span class="cov0" title="0">{
        // Get instance IP
        instanceIP, err := GetInstancePrivateIP(ctx, ra.clients, instance.ResourceID)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to get instance IP: %w", err)
        }</span>

        // Start QEMU with attached volume
        <span class="cov0" title="0">if err := ra.qemuManager.StartQEMUWithVolume(ctx, instanceIP, volume.ResourceID); err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to start QEMU: %w", err)
        }</span>

        <span class="cov0" title="0">return instanceIP, nil</span>
}

// rollbackInstanceStatus rolls back instance status with error logging
func (ra *ResourceAllocator) rollbackInstanceStatus(ctx context.Context, instanceID string) <span class="cov0" title="0">{
        if rollbackErr := UpdateInstanceStatus(ctx, ra.clients, instanceID, ResourceStatusFree); rollbackErr != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to rollback instance status", "error", rollbackErr)
        }</span>
}

// rollbackAllocation rolls back both instance and volume status
func (ra *ResourceAllocator) rollbackAllocation(ctx context.Context, instanceID, volumeID string) <span class="cov0" title="0">{
        ra.rollbackInstanceStatus(ctx, instanceID)
        if rollbackErr := UpdateVolumeStatus(ctx, ra.clients, volumeID, ResourceStatusFree); rollbackErr != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to rollback volume status", "error", rollbackErr)
        }</span>
}

// ReleaseResources marks allocated resources as free and stops QEMU
func (ra *ResourceAllocator) ReleaseResources(ctx context.Context, instanceID, volumeID string) error <span class="cov0" title="0">{
        // Get instance IP for QEMU operations
        instanceIP, err := GetInstancePrivateIP(ctx, ra.clients, instanceID)
        if err != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to get instance IP for cleanup", "instance_id", instanceID, "error", err)
        }</span> else<span class="cov0" title="0"> {
                // Stop QEMU (best effort)
                if err := ra.qemuManager.StopQEMU(ctx, instanceIP); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to stop QEMU during cleanup", "instance_ip", instanceIP, "error", err)
                }</span>
        }

        // Mark resources as free
        <span class="cov0" title="0">var errs []error

        if err := UpdateInstanceStatus(ctx, ra.clients, instanceID, ResourceStatusFree); err != nil </span><span class="cov0" title="0">{
                errs = append(errs, fmt.Errorf("failed to free instance: %w", err))
        }</span>

        <span class="cov0" title="0">if err := UpdateVolumeStatus(ctx, ra.clients, volumeID, ResourceStatusFree); err != nil </span><span class="cov0" title="0">{
                errs = append(errs, fmt.Errorf("failed to free volume: %w", err))
        }</span>

        <span class="cov0" title="0">if len(errs) &gt; 0 </span><span class="cov0" title="0">{
                return errors.Join(errs...)
        }</span>

        <span class="cov0" title="0">slog.Info("resources released", "instance_id", instanceID, "volume_id", volumeID)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resourcegraph/armresourcegraph"
)

// ResourceInfo represents basic information about an Azure resource
type ResourceInfo struct {
        ID         string
        Name       string
        Location   string
        Tags       map[string]string
        LastUsed   *time.Time
        CreatedAt  *time.Time
        Status     string
        Role       string
        ResourceID string // For volumes, this is the volumeID; for instances, this is instanceID
}

// ResourceCounts represents counts of resources by status
type ResourceCounts struct {
        Free      int
        Connected int
        Attached  int
        Total     int
}

// ResourceGraphQueries provides centralized Azure Resource Graph query operations
type ResourceGraphQueries struct {
        client         *armresourcegraph.Client
        subscriptionID string
        resourceGroup  string
}

// NewResourceGraphQueries creates a new Resource Graph query handler
func NewResourceGraphQueries(client *armresourcegraph.Client, subscriptionID, resourceGroup string) *ResourceGraphQueries <span class="cov0" title="0">{
        return &amp;ResourceGraphQueries{
                client:         client,
                subscriptionID: subscriptionID,
                resourceGroup:  resourceGroup,
        }
}</span>

// KQL query templates
const (
        // Count resources by status
        queryCountByStatus = `Resources
| where type =~ '%s'
| where tags['%s'] =~ '%s'
| where resourceGroup =~ '%s'
| summarize count() by tostring(tags['%s'])`

        // Get resources by status with details
        queryResourcesByStatus = `Resources
| where type =~ '%s'
| where tags['%s'] =~ '%s'
| where tags['%s'] =~ '%s'
| where resourceGroup =~ '%s'
| project name, id, tags, location`

        // Get oldest free resources for scale-down
        queryOldestFreeResources = `Resources
| where type =~ '%s'
| where tags['%s'] =~ '%s'
| where tags['%s'] =~ 'free'
| where resourceGroup =~ '%s'
| project name, id, tags, location, lastused=todatetime(tags['%s'])
| order by lastused asc
| take %d`

        // Get all resources of a specific role
        queryResourcesByRole = `Resources
| where type =~ '%s'
| where tags['%s'] =~ '%s'
| where resourceGroup =~ '%s'
| project name, id, tags, location`
)

// CountInstancesByStatus returns count of instances grouped by status
func (rq *ResourceGraphQueries) CountInstancesByStatus(ctx context.Context) (*ResourceCounts, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryCountByStatus,
                AzureResourceTypeVM,
                TagKeyRole,
                ResourceRoleInstance,
                rq.resourceGroup,
                TagKeyStatus)

        return rq.executeCountQuery(ctx, query)
}</span>

// CountVolumesByStatus returns count of volumes grouped by status
func (rq *ResourceGraphQueries) CountVolumesByStatus(ctx context.Context) (*ResourceCounts, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryCountByStatus,
                AzureResourceTypeDisk,
                TagKeyRole,
                ResourceRoleVolume,
                rq.resourceGroup,
                TagKeyStatus)

        return rq.executeCountQuery(ctx, query)
}</span>

// GetInstancesByStatus returns instances with specific status
func (rq *ResourceGraphQueries) GetInstancesByStatus(ctx context.Context, status string) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryResourcesByStatus,
                AzureResourceTypeVM,
                TagKeyRole,
                ResourceRoleInstance,
                TagKeyStatus,
                status,
                rq.resourceGroup)

        return rq.executeResourceQuery(ctx, query)
}</span>

// GetVolumesByStatus returns volumes with specific status
func (rq *ResourceGraphQueries) GetVolumesByStatus(ctx context.Context, status string) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryResourcesByStatus,
                AzureResourceTypeDisk,
                TagKeyRole,
                ResourceRoleVolume,
                TagKeyStatus,
                status,
                rq.resourceGroup)

        return rq.executeResourceQuery(ctx, query)
}</span>

// GetOldestFreeInstances returns oldest free instances for scale-down decisions
func (rq *ResourceGraphQueries) GetOldestFreeInstances(ctx context.Context, limit int) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryOldestFreeResources,
                AzureResourceTypeVM,
                TagKeyRole,
                ResourceRoleInstance,
                TagKeyStatus,
                rq.resourceGroup,
                TagKeyLastUsed,
                limit)

        return rq.executeResourceQuery(ctx, query)
}</span>

// GetOldestFreeVolumes returns oldest free volumes for scale-down decisions
func (rq *ResourceGraphQueries) GetOldestFreeVolumes(ctx context.Context, limit int) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryOldestFreeResources,
                AzureResourceTypeDisk,
                TagKeyRole,
                ResourceRoleVolume,
                TagKeyStatus,
                rq.resourceGroup,
                TagKeyLastUsed,
                limit)

        return rq.executeResourceQuery(ctx, query)
}</span>

// GetAllInstances returns all instances regardless of status
func (rq *ResourceGraphQueries) GetAllInstances(ctx context.Context) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryResourcesByRole,
                AzureResourceTypeVM,
                TagKeyRole,
                ResourceRoleInstance,
                rq.resourceGroup)

        return rq.executeResourceQuery(ctx, query)
}</span>

// GetAllVolumes returns all volumes regardless of status
func (rq *ResourceGraphQueries) GetAllVolumes(ctx context.Context) ([]ResourceInfo, error) <span class="cov0" title="0">{
        query := fmt.Sprintf(queryResourcesByRole,
                AzureResourceTypeDisk,
                TagKeyRole,
                ResourceRoleVolume,
                rq.resourceGroup)

        return rq.executeResourceQuery(ctx, query)
}</span>

// executeCountQuery executes a count query and returns ResourceCounts
func (rq *ResourceGraphQueries) executeCountQuery(ctx context.Context, query string) (*ResourceCounts, error) <span class="cov0" title="0">{
        slog.Debug("executing Resource Graph count query", "query", query)

        result, err := rq.client.Resources(ctx, armresourcegraph.QueryRequest{
                Query: to.Ptr(query),
                Subscriptions: []*string{
                        to.Ptr(rq.subscriptionID),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resource Graph query failed: %w", err)
        }</span>

        <span class="cov0" title="0">counts := &amp;ResourceCounts{}

        // Parse the aggregation results
        if result.Data != nil </span><span class="cov0" title="0">{
                if dataArray, ok := result.Data.([]interface{}); ok </span><span class="cov0" title="0">{
                        for _, item := range dataArray </span><span class="cov0" title="0">{
                                if row, ok := item.([]interface{}); ok &amp;&amp; len(row) == 2 </span><span class="cov0" title="0">{
                                        if statusInterface, countInterface := row[0], row[1]; statusInterface != nil &amp;&amp; countInterface != nil </span><span class="cov0" title="0">{
                                                status := fmt.Sprintf("%v", statusInterface)
                                                if countFloat, ok := countInterface.(float64); ok </span><span class="cov0" title="0">{
                                                        count := int(countFloat)
                                                        switch status </span>{
                                                        case ResourceStatusFree:<span class="cov0" title="0">
                                                                counts.Free = count</span>
                                                        case ResourceStatusConnected:<span class="cov0" title="0">
                                                                counts.Connected = count</span>
                                                        case ResourceStatusAttached:<span class="cov0" title="0">
                                                                counts.Attached = count</span>
                                                        }
                                                        <span class="cov0" title="0">counts.Total += count</span>
                                                }
                                        }
                                }
                        }
                }
        }

        <span class="cov0" title="0">slog.Debug("Resource Graph count query result",
                "free", counts.Free,
                "connected", counts.Connected,
                "attached", counts.Attached,
                "total", counts.Total)

        return counts, nil</span>
}

// executeResourceQuery executes a resource listing query and returns ResourceInfo slice
func (rq *ResourceGraphQueries) executeResourceQuery(ctx context.Context, query string) ([]ResourceInfo, error) <span class="cov0" title="0">{
        slog.Debug("executing Resource Graph resource query", "query", query)

        result, err := rq.client.Resources(ctx, armresourcegraph.QueryRequest{
                Query: to.Ptr(query),
                Subscriptions: []*string{
                        to.Ptr(rq.subscriptionID),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("resource Graph query failed: %w", err)
        }</span>

        <span class="cov0" title="0">var resources []ResourceInfo

        // Parse the resource results
        if result.Data != nil </span><span class="cov0" title="0">{
                if dataArray, ok := result.Data.([]interface{}); ok </span><span class="cov0" title="0">{
                        for _, item := range dataArray </span><span class="cov0" title="0">{
                                if resourceMap, ok := item.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                                        resource := parseResourceInfo(resourceMap)
                                        if resource != nil </span><span class="cov0" title="0">{
                                                resources = append(resources, *resource)
                                        }</span>
                                }
                        }
                }
        }

        <span class="cov0" title="0">slog.Debug("Resource Graph resource query result", "count", len(resources))
        return resources, nil</span>
}

// parseResourceInfo converts Resource Graph result map to ResourceInfo struct
func parseResourceInfo(resourceMap map[string]interface{}) *ResourceInfo <span class="cov0" title="0">{
        resource := &amp;ResourceInfo{}

        parseBasicFields(resource, resourceMap)
        parseTags(resource, resourceMap)
        parseProjectedFields(resource, resourceMap)

        return resource
}</span>

// parseBasicFields extracts basic resource fields
func parseBasicFields(resource *ResourceInfo, resourceMap map[string]interface{}) <span class="cov0" title="0">{
        if name, ok := resourceMap["name"].(string); ok </span><span class="cov0" title="0">{
                resource.Name = name
        }</span>
        <span class="cov0" title="0">if id, ok := resourceMap["id"].(string); ok </span><span class="cov0" title="0">{
                resource.ID = id
        }</span>
        <span class="cov0" title="0">if location, ok := resourceMap["location"].(string); ok </span><span class="cov0" title="0">{
                resource.Location = location
        }</span>
}

// parseTags extracts and processes resource tags
func parseTags(resource *ResourceInfo, resourceMap map[string]interface{}) <span class="cov0" title="0">{
        tagsInterface, ok := resourceMap["tags"]
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">tagsMap, ok := tagsInterface.(map[string]interface{})
        if !ok </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">resource.Tags = make(map[string]string)
        for k, v := range tagsMap </span><span class="cov0" title="0">{
                if vStr, ok := v.(string); ok </span><span class="cov0" title="0">{
                        resource.Tags[k] = vStr
                }</span>
        }

        <span class="cov0" title="0">extractTagValues(resource)
        parseTimestamps(resource)
        extractResourceID(resource)</span>
}

// extractTagValues extracts specific tag values
func extractTagValues(resource *ResourceInfo) <span class="cov0" title="0">{
        resource.Status = resource.Tags[TagKeyStatus]
        resource.Role = resource.Tags[TagKeyRole]
}</span>

// parseTimestamps parses timestamp strings from tags
func parseTimestamps(resource *ResourceInfo) <span class="cov0" title="0">{
        if createdStr := resource.Tags[TagKeyCreated]; createdStr != "" </span><span class="cov0" title="0">{
                if created, err := time.Parse(time.RFC3339, createdStr); err == nil </span><span class="cov0" title="0">{
                        resource.CreatedAt = &amp;created
                }</span>
        }
        <span class="cov0" title="0">if lastUsedStr := resource.Tags[TagKeyLastUsed]; lastUsedStr != "" </span><span class="cov0" title="0">{
                if lastUsed, err := time.Parse(time.RFC3339, lastUsedStr); err == nil </span><span class="cov0" title="0">{
                        resource.LastUsed = &amp;lastUsed
                }</span>
        }
}

// extractResourceID extracts resource ID from tags (instance_id or volume_id)
func extractResourceID(resource *ResourceInfo) <span class="cov0" title="0">{
        if instanceID := resource.Tags["instance_id"]; instanceID != "" </span><span class="cov0" title="0">{
                resource.ResourceID = instanceID
        }</span>
        <span class="cov0" title="0">if volumeID := resource.Tags["volume_id"]; volumeID != "" </span><span class="cov0" title="0">{
                resource.ResourceID = volumeID
        }</span>
}

// parseProjectedFields parses fields projected by specific queries
func parseProjectedFields(resource *ResourceInfo, resourceMap map[string]interface{}) <span class="cov0" title="0">{
        // Parse lastused from query projection (for oldest resource queries)
        if lastUsedInterface, ok := resourceMap["lastused"]; ok </span><span class="cov0" title="0">{
                if lastUsedStr, ok := lastUsedInterface.(string); ok </span><span class="cov0" title="0">{
                        if lastUsed, err := time.Parse(time.RFC3339, lastUsedStr); err == nil </span><span class="cov0" title="0">{
                                resource.LastUsed = &amp;lastUsed
                        }</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file11" style="display: none">package infra

import "fmt"

type ResourceNamer struct {
        suffix string
}

func NewResourceNamer(suffix string) *ResourceNamer <span class="cov8" title="1">{
        return &amp;ResourceNamer{suffix: suffix}
}</span>

func (r *ResourceNamer) ResourceGroup() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s", r.suffix)
}</span>

func (r *ResourceNamer) VNetName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-vnet", r.suffix)
}</span>

func (r *ResourceNamer) BastionSubnetName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-subnet", r.suffix)
}</span>

func (r *ResourceNamer) BoxesSubnetName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-boxes-subnet", r.suffix)
}</span>

func (r *ResourceNamer) BastionNSGName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-nsg", r.suffix)
}</span>

func (r *ResourceNamer) BoxNSGName(boxID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-box-%s-nsg", r.suffix, boxID)
}</span>

func (r *ResourceNamer) BastionVMName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-vm", r.suffix)
}</span>

func (r *ResourceNamer) BoxVMName(boxID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-box-%s-vm", r.suffix, boxID)
}</span>

func (r *ResourceNamer) BastionComputerName() string <span class="cov8" title="1">{
        return "shellbox-bastion"
}</span>

func (r *ResourceNamer) BoxComputerName(boxID string) string <span class="cov8" title="1">{
        if len(boxID) &gt; 8 </span><span class="cov8" title="1">{
                return fmt.Sprintf("shellbox-box-%s", boxID[:8])
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("shellbox-box-%s", boxID)</span>
}

func (r *ResourceNamer) BastionNICName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-nic", r.suffix)
}</span>

func (r *ResourceNamer) BoxNICName(boxID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-box-%s-nic", r.suffix, boxID)
}</span>

func (r *ResourceNamer) BastionPublicIPName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-pip", r.suffix)
}</span>

func (r *ResourceNamer) BastionOSDiskName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-bastion-os-disk", r.suffix)
}</span>

func (r *ResourceNamer) BoxOSDiskName(boxID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-box-%s-os-disk", r.suffix, boxID)
}</span>

func (r *ResourceNamer) StorageAccountName() string <span class="cov8" title="1">{
        // Storage account names must be 3-24 chars, lowercase letters and numbers only
        // Remove hyphens and truncate suffix if needed
        cleanSuffix := ""
        for _, char := range r.suffix </span><span class="cov8" title="1">{
                if (char &gt;= 'a' &amp;&amp; char &lt;= 'z') || (char &gt;= '0' &amp;&amp; char &lt;= '9') </span><span class="cov8" title="1">{
                        cleanSuffix += string(char)
                }</span>
        }
        // Ensure total length is &lt;= 24 chars
        <span class="cov8" title="1">prefix := "sb" // shortened from "shellbox"
        maxSuffixLen := 24 - len(prefix)
        if len(cleanSuffix) &gt; maxSuffixLen </span><span class="cov0" title="0">{
                cleanSuffix = cleanSuffix[:maxSuffixLen]
        }</span>
        <span class="cov8" title="1">return fmt.Sprintf("%s%s", prefix, cleanSuffix)</span>
}

func (r *ResourceNamer) GoldenSnapshotName() string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-golden-snapshot", r.suffix)
}</span>

func (r *ResourceNamer) BoxDataDiskName(boxID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-box-%s-data-disk", r.suffix, boxID)
}</span>

func (r *ResourceNamer) VolumePoolDiskName(volumeID string) string <span class="cov8" title="1">{
        return fmt.Sprintf("shellbox-%s-volume-%s", r.suffix, volumeID)
}</span>

// SharedStorageAccountName returns the shared storage account name for testing
func (r *ResourceNamer) SharedStorageAccountName() string <span class="cov8" title="1">{
        return TestingStorageAccountBaseName
}</span>

// EventLogTableName returns the suffixed table name for EventLog
func (r *ResourceNamer) EventLogTableName() string <span class="cov8" title="1">{
        cleanSuffix := r.cleanSuffixForTable()
        return fmt.Sprintf("%s%s", tableEventLogBase, cleanSuffix)
}</span>

// ResourceRegistryTableName returns the suffixed table name for ResourceRegistry
func (r *ResourceNamer) ResourceRegistryTableName() string <span class="cov8" title="1">{
        cleanSuffix := r.cleanSuffixForTable()
        return fmt.Sprintf("%s%s", tableResourceRegistryBase, cleanSuffix)
}</span>

// cleanSuffixForTable removes invalid characters from suffix for Azure Table names
// Table names can only contain alphanumeric characters
func (r *ResourceNamer) cleanSuffixForTable() string <span class="cov8" title="1">{
        cleanSuffix := ""
        for _, char := range r.suffix </span><span class="cov8" title="1">{
                if (char &gt;= 'a' &amp;&amp; char &lt;= 'z') || (char &gt;= 'A' &amp;&amp; char &lt;= 'Z') || (char &gt;= '0' &amp;&amp; char &lt;= '9') </span><span class="cov8" title="1">{
                        cleanSuffix += string(char)
                }</span>
        }
        <span class="cov8" title="1">return cleanSuffix</span>
}
</pre>
		
		<pre class="file" id="file12" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "time"
)

// RetryOperation executes an operation with retries until success or timeout
func RetryOperation(ctx context.Context, operation func(context.Context) error, timeout time.Duration, interval time.Duration, operationName string) error <span class="cov8" title="1">{
        ctx, cancel := context.WithTimeout(ctx, timeout)
        defer cancel()

        ticker := time.NewTicker(interval)
        defer ticker.Stop()

        var lastErr error

        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov8" title="1">
                        if lastErr != nil </span><span class="cov8" title="1">{
                                return fmt.Errorf("timeout waiting for %s: %w", operationName, lastErr)
                        }</span>
                        <span class="cov0" title="0">return fmt.Errorf("timeout waiting for %s", operationName)</span>
                case &lt;-ticker.C:<span class="cov8" title="1">
                        err := operation(ctx)
                        if err == nil </span><span class="cov8" title="1">{
                                slog.Info("operation completed successfully", "operation", operationName)
                                return nil
                        }</span>
                        <span class="cov8" title="1">lastErr = err
                        slog.Warn("retrying operation", "operation", operationName, "error", err)</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file13" style="display: none">package infra

import (
        "context"
        "encoding/json"
        "errors"
        "fmt"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore"
        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/data/aztables"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/storage/armstorage"
)

// TableStorageResult contains the result of the Table Storage creation operation
type TableStorageResult struct {
        ConnectionString string
        Error            error
}

// CreateTableStorageResources creates a storage account and tables
func CreateTableStorageResources(ctx context.Context, clients *AzureClients, accountName string, tableNames []string) TableStorageResult <span class="cov0" title="0">{
        result := TableStorageResult{}

        storageClient, err := armstorage.NewAccountsClient(clients.SubscriptionID, clients.Cred, nil)
        if err != nil </span><span class="cov0" title="0">{
                result.Error = fmt.Errorf("failed to create storage client: %w", err)
                return result
        }</span>

        // Ensure storage account exists
        <span class="cov0" title="0">if err := ensureStorageAccountExists(ctx, storageClient, clients.ResourceGroupName, accountName); err != nil </span><span class="cov0" title="0">{
                result.Error = err
                return result
        }</span>

        // Get connection string
        <span class="cov0" title="0">connectionString, err := getStorageConnectionString(ctx, storageClient, clients.ResourceGroupName, accountName)
        if err != nil </span><span class="cov0" title="0">{
                result.Error = err
                return result
        }</span>
        <span class="cov0" title="0">result.ConnectionString = connectionString

        // Create tables
        if err := createTables(ctx, connectionString, tableNames); err != nil </span><span class="cov0" title="0">{
                result.Error = err
                return result
        }</span>

        <span class="cov0" title="0">return result</span>
}

// ensureStorageAccountExists checks if storage account exists and creates it if needed
func ensureStorageAccountExists(ctx context.Context, storageClient *armstorage.AccountsClient, resourceGroupName, accountName string) error <span class="cov0" title="0">{
        // Check if storage account already exists in our resource group
        _, err := storageClient.GetProperties(ctx, resourceGroupName, accountName, nil)
        if err == nil </span><span class="cov0" title="0">{
                return nil // Already exists
        }</span>

        // Storage account doesn't exist, check name availability
        <span class="cov0" title="0">checkAvailability, err := storageClient.CheckNameAvailability(ctx, armstorage.AccountCheckNameAvailabilityParameters{
                Name: to.Ptr(accountName),
                Type: to.Ptr("Microsoft.Storage/storageAccounts"),
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to check storage account name availability: %w", err)
        }</span>

        <span class="cov0" title="0">if !*checkAvailability.NameAvailable </span><span class="cov0" title="0">{
                return fmt.Errorf("storage account name '%s' is not available: %s", accountName, *checkAvailability.Message)
        }</span>

        // Create the storage account
        <span class="cov0" title="0">poller, err := storageClient.BeginCreate(ctx, resourceGroupName, accountName, armstorage.AccountCreateParameters{
                SKU: &amp;armstorage.SKU{
                        Name: to.Ptr(armstorage.SKUNameStandardLRS),
                },
                Kind:     to.Ptr(armstorage.KindStorageV2),
                Location: to.Ptr(Location),
                Properties: &amp;armstorage.AccountPropertiesCreateParameters{
                        AllowBlobPublicAccess: to.Ptr(false),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create storage account: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to wait for storage account creation: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// getStorageConnectionString retrieves the connection string for a storage account
func getStorageConnectionString(ctx context.Context, storageClient *armstorage.AccountsClient, resourceGroupName, accountName string) (string, error) <span class="cov0" title="0">{
        var keysResponse armstorage.AccountsClientListKeysResponse

        // Retry getting storage keys in case the storage account is still provisioning
        err := RetryOperation(ctx, func(ctx context.Context) error </span><span class="cov0" title="0">{
                var err error
                keysResponse, err = storageClient.ListKeys(ctx, resourceGroupName, accountName, nil)
                return err
        }</span>, 5*time.Minute, 10*time.Second, "get storage account keys")
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to get storage keys: %w", err)
        }</span>

        <span class="cov0" title="0">if len(keysResponse.Keys) == 0 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("no storage keys found")
        }</span>

        <span class="cov0" title="0">key := *keysResponse.Keys[0].Value
        return fmt.Sprintf("DefaultEndpointsProtocol=https;AccountName=%s;AccountKey=%s;EndpointSuffix=core.windows.net", accountName, key), nil</span>
}

// createTables creates the specified tables in the storage account
func createTables(ctx context.Context, connectionString string, tableNames []string) error <span class="cov0" title="0">{
        tablesClient, err := aztables.NewServiceClientFromConnectionString(connectionString, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create tables client: %w", err)
        }</span>

        // Use legacy defaults if no table names provided
        <span class="cov0" title="0">if len(tableNames) == 0 </span><span class="cov0" title="0">{
                tableNames = []string{tableEventLog, tableResourceRegistry}
        }</span>

        <span class="cov0" title="0">for _, tableName := range tableNames </span><span class="cov0" title="0">{
                _, err = tablesClient.CreateTable(ctx, tableName, nil)
                if err != nil </span><span class="cov0" title="0">{
                        // Check if this is a "table already exists" error (idempotent operation)
                        var respErr *azcore.ResponseError
                        if errors.As(err, &amp;respErr) &amp;&amp; respErr.StatusCode == 409 &amp;&amp; respErr.ErrorCode == "TableAlreadyExists" </span><span class="cov0" title="0">{
                                continue</span> // Table already exists, this is fine
                        }
                        <span class="cov0" title="0">return fmt.Errorf("failed to create table %s: %w", tableName, err)</span>
                }
        }

        <span class="cov0" title="0">return nil</span>
}

// CreateTableStorageResourcesLegacy creates a storage account with default table names (backward compatibility)
func CreateTableStorageResourcesLegacy(ctx context.Context, clients *AzureClients, accountName string) TableStorageResult <span class="cov0" title="0">{
        return CreateTableStorageResources(ctx, clients, accountName, nil)
}</span>

// EventLogEntity represents an entry in the EventLog table
type EventLogEntity struct {
        PartitionKey string    `json:"PartitionKey"`
        RowKey       string    `json:"RowKey"`
        Timestamp    time.Time `json:"Timestamp"`
        EventType    string    `json:"EventType"`
        SessionID    string    `json:"SessionID,omitempty"`
        BoxID        string    `json:"BoxID,omitempty"`
        UserKey      string    `json:"UserKey,omitempty"`
        Details      string    `json:"Details,omitempty"`
}

// ResourceRegistryEntity represents an entry in the ResourceRegistry table
type ResourceRegistryEntity struct {
        PartitionKey string    `json:"PartitionKey"`
        RowKey       string    `json:"RowKey"`
        Timestamp    time.Time `json:"Timestamp"`
        Status       string    `json:"Status"`
        VMName       string    `json:"VMName,omitempty"`
        CreatedAt    time.Time `json:"CreatedAt"`
        LastActivity time.Time `json:"LastActivity"`
        Metadata     string    `json:"Metadata,omitempty"`
}

// writeTableEntity is a generic function for writing entities to Azure Tables
func writeTableEntity(ctx context.Context, clients *AzureClients, tableName string, entity interface{}) error <span class="cov0" title="0">{
        if clients.TableClient == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("table client not available")
        }</span>

        <span class="cov0" title="0">tableClient := clients.TableClient.NewClient(tableName)
        entityBytes, err := json.Marshal(entity)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal entity: %w", err)
        }</span>
        <span class="cov0" title="0">_, err = tableClient.AddEntity(ctx, entityBytes, nil)
        return err</span>
}

// WriteEventLog writes an entry to the EventLog table
func WriteEventLog(ctx context.Context, clients *AzureClients, event EventLogEntity) error <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        tableName := namer.EventLogTableName()
        return writeTableEntity(ctx, clients, tableName, event)
}</span>

// WriteResourceRegistry writes an entry to the ResourceRegistry table
func WriteResourceRegistry(ctx context.Context, clients *AzureClients, resource ResourceRegistryEntity) error <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        tableName := namer.ResourceRegistryTableName()
        return writeTableEntity(ctx, clients, tableName, resource)
}</span>

// WriteEventLogLegacy writes an entry to the EventLog table using legacy table name (backward compatibility)
func WriteEventLogLegacy(ctx context.Context, clients *AzureClients, event EventLogEntity) error <span class="cov0" title="0">{
        return writeTableEntity(ctx, clients, tableEventLog, event)
}</span>

// WriteResourceRegistryLegacy writes an entry to the ResourceRegistry table using legacy table name (backward compatibility)
func WriteResourceRegistryLegacy(ctx context.Context, clients *AzureClients, resource ResourceRegistryEntity) error <span class="cov0" title="0">{
        return writeTableEntity(ctx, clients, tableResourceRegistry, resource)
}</span>

// CleanupTestTables deletes test tables with the given suffix (for test cleanup)
func CleanupTestTables(ctx context.Context, clients *AzureClients, suffix string) error <span class="cov0" title="0">{
        if clients.TableClient == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("table client not available")
        }</span>

        <span class="cov0" title="0">namer := NewResourceNamer(suffix)
        tableNames := []string{namer.EventLogTableName(), namer.ResourceRegistryTableName()}

        for _, tableName := range tableNames </span><span class="cov0" title="0">{
                _, err := clients.TableClient.DeleteTable(ctx, tableName, nil)
                if err != nil </span><span class="cov0" title="0">{
                        // Log but don't fail on cleanup errors
                        return fmt.Errorf("failed to delete table %s: %w", tableName, err)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">package infra

import (
        "context"
        "fmt"
        "log/slog"
        "strings"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/runtime"
        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/google/uuid"
)

// VolumeTags represents searchable metadata for volume disks.
// These tags are used to track volume status and lifecycle.
type VolumeTags struct {
        Role      string // volume, temp, golden
        Status    string // free, attached
        CreatedAt string
        LastUsed  string
        VolumeID  string
}

// VolumeConfig represents configuration for creating a volume
type VolumeConfig struct {
        DiskSize int32
}

// VolumeInfo contains information about a created volume
type VolumeInfo struct {
        Name       string
        ResourceID string
        Location   string
        SizeGB     int32
        VolumeID   string
        Tags       VolumeTags
}

// CreateVolume creates a new empty managed disk volume with standard configuration.
// This is a simplified version that uses a VolumeConfig and generates appropriate defaults.
// It returns the volume ID and any error encountered.
func CreateVolume(ctx context.Context, clients *AzureClients, config *VolumeConfig) (string, error) <span class="cov0" title="0">{
        volumeID := uuid.New().String()
        namer := NewResourceNamer(clients.Suffix)
        volumeName := namer.VolumePoolDiskName(volumeID)

        now := time.Now().UTC()
        tags := VolumeTags{
                Role:      ResourceRoleVolume,
                Status:    ResourceStatusFree,
                CreatedAt: now.Format(time.RFC3339),
                LastUsed:  now.Format(time.RFC3339),
                VolumeID:  volumeID,
        }

        _, err := CreateVolumeWithTags(ctx, clients, clients.ResourceGroupName, volumeName, config.DiskSize, tags)
        if err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>

        <span class="cov0" title="0">return volumeID, nil</span>
}

// CreateVolumeWithTags creates a new empty managed disk volume with proper tagging.
// This creates a standard empty volume that can be used for temporary purposes
// or as a base for QEMU setup. It returns volume information and any error encountered.
func CreateVolumeWithTags(ctx context.Context, clients *AzureClients, resourceGroupName, volumeName string, sizeGB int32, tags VolumeTags) (*VolumeInfo, error) <span class="cov0" title="0">{
        now := time.Now().UTC()
        if tags.VolumeID == "" </span><span class="cov0" title="0">{
                tags.VolumeID = uuid.New().String()
        }</span>
        <span class="cov0" title="0">if tags.CreatedAt == "" </span><span class="cov0" title="0">{
                tags.CreatedAt = now.Format(time.RFC3339)
        }</span>
        <span class="cov0" title="0">if tags.LastUsed == "" </span><span class="cov0" title="0">{
                tags.LastUsed = now.Format(time.RFC3339)
        }</span>

        <span class="cov0" title="0">slog.Info("Creating volume", "name", volumeName, "sizeGB", sizeGB, "role", tags.Role)

        diskParams := armcompute.Disk{
                Location: to.Ptr(Location),
                Properties: &amp;armcompute.DiskProperties{
                        DiskSizeGB: to.Ptr(sizeGB),
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption: to.Ptr(armcompute.DiskCreateOptionEmpty),
                        },
                },
                Tags: volumeTagsToMap(tags),
        }

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, resourceGroupName, volumeName, diskParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting volume creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating volume: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;VolumeInfo{
                Name:       *result.Name,
                ResourceID: *result.ID,
                Location:   *result.Location,
                SizeGB:     *result.Properties.DiskSizeGB,
                VolumeID:   tags.VolumeID,
                Tags:       tags,
        }, nil</span>
}

// CreateVolumeFromSnapshot creates a new managed disk volume from an existing snapshot.
// This is used to create user volumes from golden snapshots or restore from backups.
// It returns volume information and any error encountered.
func CreateVolumeFromSnapshot(ctx context.Context, clients *AzureClients, resourceGroupName, volumeName, snapshotID string, tags VolumeTags) (*VolumeInfo, error) <span class="cov0" title="0">{
        now := time.Now().UTC()
        if tags.VolumeID == "" </span><span class="cov0" title="0">{
                tags.VolumeID = uuid.New().String()
        }</span>
        <span class="cov0" title="0">if tags.CreatedAt == "" </span><span class="cov0" title="0">{
                tags.CreatedAt = now.Format(time.RFC3339)
        }</span>
        <span class="cov0" title="0">if tags.LastUsed == "" </span><span class="cov0" title="0">{
                tags.LastUsed = now.Format(time.RFC3339)
        }</span>

        <span class="cov0" title="0">slog.Info("Creating volume from snapshot", "snapshotID", snapshotID, "volumeName", volumeName, "role", tags.Role)

        diskParams := armcompute.Disk{
                Location: to.Ptr(Location),
                Properties: &amp;armcompute.DiskProperties{
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption:     to.Ptr(armcompute.DiskCreateOptionCopy),
                                SourceResourceID: to.Ptr(snapshotID),
                        },
                },
                Tags: volumeTagsToMap(tags),
        }

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, resourceGroupName, volumeName, diskParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting volume creation from snapshot: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating volume from snapshot: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;VolumeInfo{
                Name:       *result.Name,
                ResourceID: *result.ID,
                Location:   *result.Location,
                SizeGB:     *result.Properties.DiskSizeGB,
                VolumeID:   tags.VolumeID,
                Tags:       tags,
        }, nil</span>
}

// DeleteVolume completely removes a managed disk volume.
// This function handles cleanup for temporary volumes, user volumes, or any managed disk.
// It returns an error if the deletion fails.
func DeleteVolume(ctx context.Context, clients *AzureClients, resourceGroupName, volumeName string) error <span class="cov0" title="0">{
        if volumeName == "" </span><span class="cov0" title="0">{
                slog.Warn("Volume name is empty, skipping deletion")
                return nil
        }</span>

        <span class="cov0" title="0">slog.Info("Deleting volume", "name", volumeName)

        pollOptions := &amp;runtime.PollUntilDoneOptions{
                Frequency: 2 * time.Second,
        }

        poller, err := clients.DisksClient.BeginDelete(ctx, resourceGroupName, volumeName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("starting volume deletion: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, pollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("deleting volume: %w", err)
        }</span>

        <span class="cov0" title="0">slog.Info("Successfully deleted volume", "name", volumeName)
        return nil</span>
}

// FindVolumesByRole returns volume names matching the given role tag.
// It filters disks based on their role tag and returns their names for further operations.
// If suffix is provided, it only returns volumes whose names contain that suffix.
func FindVolumesByRole(ctx context.Context, clients *AzureClients, resourceGroupName, role string, suffix ...string) ([]string, error) <span class="cov0" title="0">{
        var volumes []string

        pager := clients.DisksClient.NewListByResourceGroupPager(resourceGroupName, nil)
        for pager.More() </span><span class="cov0" title="0">{
                page, err := pager.NextPage(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("listing volumes: %w", err)
                }</span>

                <span class="cov0" title="0">for _, disk := range page.Value </span><span class="cov0" title="0">{
                        if disk.Tags != nil </span><span class="cov0" title="0">{
                                if roleTag, exists := disk.Tags[TagKeyRole]; exists &amp;&amp; *roleTag == role </span><span class="cov0" title="0">{
                                        // If suffix filter is provided, only include volumes with that suffix in the name
                                        if len(suffix) &gt; 0 &amp;&amp; !strings.Contains(*disk.Name, suffix[0]) </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">volumes = append(volumes, *disk.Name)</span>
                                }
                        }
                }
        }

        <span class="cov0" title="0">return volumes, nil</span>
}

// volumeTagsToMap converts VolumeTags struct to Azure tags map format
func volumeTagsToMap(tags VolumeTags) map[string]*string <span class="cov0" title="0">{
        return map[string]*string{
                TagKeyRole:     to.Ptr(tags.Role),
                TagKeyStatus:   to.Ptr(tags.Status),
                TagKeyCreated:  to.Ptr(tags.CreatedAt),
                TagKeyLastUsed: to.Ptr(tags.LastUsed),
                "volume_id":    to.Ptr(tags.VolumeID),
        }
}</span>

// UpdateVolumeStatus updates the status tag of a volume
func UpdateVolumeStatus(ctx context.Context, clients *AzureClients, volumeID, status string) error <span class="cov0" title="0">{
        namer := NewResourceNamer(clients.Suffix)
        volumeName := namer.VolumePoolDiskName(volumeID)

        // Get current volume
        volume, err := clients.DisksClient.Get(ctx, clients.ResourceGroupName, volumeName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get volume for status update: %w", err)
        }</span>

        // Update status tag
        <span class="cov0" title="0">if volume.Tags == nil </span><span class="cov0" title="0">{
                volume.Tags = make(map[string]*string)
        }</span>
        <span class="cov0" title="0">volume.Tags[TagKeyStatus] = to.Ptr(status)
        volume.Tags[TagKeyLastUsed] = to.Ptr(time.Now().UTC().Format(time.RFC3339))

        // Update the volume
        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, volumeName, volume.Disk, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start volume status update: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, &amp;DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to update volume status: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">package sshutil

import (
        "context"
        "crypto/rand"
        "crypto/rsa"
        "crypto/x509"
        "encoding/pem"
        "fmt"
        "os"
        "os/exec"
        "path/filepath"
        "strings"

        "golang.org/x/crypto/ssh"
)

// LoadKeyPair loads or creates an SSH key pair, using the private key as the source of truth.
func LoadKeyPair(keyPath string) (privateKey, publicKey string, err error) <span class="cov0" title="0">{
        expandedPath := filepath.Clean(os.ExpandEnv(keyPath))

        // Try to read private key
        privKeyData, err := os.ReadFile(expandedPath)
        if os.IsNotExist(err) </span><span class="cov0" title="0">{
                // Generate new RSA key pair
                key, err := rsa.GenerateKey(rand.Reader, 4096)
                if err != nil </span><span class="cov0" title="0">{
                        return "", "", fmt.Errorf("generating key pair: %w", err)
                }</span>

                // Create private key PEM
                <span class="cov0" title="0">privateKeyPEM := &amp;pem.Block{
                        Type:  "RSA PRIVATE KEY",
                        Bytes: x509.MarshalPKCS1PrivateKey(key),
                }
                privateKey = string(pem.EncodeToMemory(privateKeyPEM))

                // Save private key
                if err := os.WriteFile(expandedPath, []byte(privateKey), 0o600); err != nil </span><span class="cov0" title="0">{
                        return "", "", fmt.Errorf("writing private key file: %w", err)
                }</span>

                <span class="cov0" title="0">privKeyData = []byte(privateKey)</span>
        } else<span class="cov0" title="0"> if err != nil </span><span class="cov0" title="0">{
                return "", "", fmt.Errorf("reading private key: %w", err)
        }</span>

        // Parse private key
        <span class="cov0" title="0">block, _ := pem.Decode(privKeyData)
        if block == nil </span><span class="cov0" title="0">{
                return "", "", fmt.Errorf("failed to decode PEM block from private key")
        }</span>

        <span class="cov0" title="0">var signer ssh.Signer
        var parseErr error

        // Try parsing with different formats
        signer, parseErr = ssh.ParsePrivateKey(privKeyData)
        if parseErr != nil </span><span class="cov0" title="0">{
                return "", "", fmt.Errorf("parsing private key: %w", parseErr)
        }</span>

        <span class="cov0" title="0">publicKey = strings.TrimSpace(string(ssh.MarshalAuthorizedKey(signer.PublicKey())))
        privateKey = string(privKeyData)

        return privateKey, publicKey, nil</span>
}

// CopyFile copies a file to a remote host using scp
func CopyFile(ctx context.Context, localPath, remotePath, username, hostname string) error <span class="cov0" title="0">{
        scpDest := fmt.Sprintf("%s@%s:%s", username, hostname, remotePath)
        cmd := exec.CommandContext(ctx, "scp", "-o", "StrictHostKeyChecking=no", "-o", "ConnectTimeout=4", localPath, scpDest)
        if output, err := cmd.CombinedOutput(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("%w: %s", err, string(output))
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// ExecuteCommand executes a command on a remote host using SSH
func ExecuteCommand(ctx context.Context, command, username, hostname string) error <span class="cov0" title="0">{
        cmd := exec.CommandContext(ctx, "ssh",
                "-o", "StrictHostKeyChecking=no",
                "-o", "ConnectTimeout=4",
                fmt.Sprintf("%s@%s", username, hostname),
                command)
        if output, err := cmd.CombinedOutput(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("%w: %s", err, string(output))
        }</span>
        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">package test

import (
        "os"
        "strconv"
        "strings"
        "time"
)

// Category represents a category of tests with different execution characteristics
type Category string

const (
        CategoryUnit        Category = "unit"        // &lt; 30s, pure Go logic
        CategoryClient      Category = "client"      // &lt; 2m, Azure client init
        CategoryIntegration Category = "integration" // &lt; 10m, infrastructure
        CategoryCompute     Category = "compute"     // &lt; 15m, VM operations
        CategoryGolden      Category = "golden"      // &lt; 30m, snapshot operations
        CategoryPool        Category = "pool"        // &lt; 30m, pool behavior
        CategoryE2E         Category = "e2e"         // &lt; 45m, end-to-end scenarios
)

// Config holds configuration for test execution
type Config struct {
        // Category selection
        Categories []Category

        // Skip flags for expensive operations
        SkipGoldenSnapshot bool
        SkipPoolTests      bool
        SkipE2ETests       bool

        // Resource configuration
        ResourceGroupPrefix string
        Location            string
        CleanupTimeout      time.Duration

        // Execution configuration
        ParallelLimit int
        TestTimeout   time.Duration
        IsCI          bool

        // Azure configuration
        UseAzureCLI bool
}

// DefaultConfig returns the default test configuration
func DefaultConfig() *Config <span class="cov8" title="1">{
        return &amp;Config{
                Categories:          []Category{CategoryUnit},
                SkipGoldenSnapshot:  false,
                SkipPoolTests:       false,
                SkipE2ETests:        false,
                ResourceGroupPrefix: "test",
                Location:            "westus2",
                CleanupTimeout:      10 * time.Minute,
                ParallelLimit:       4,
                TestTimeout:         60 * time.Minute,
                IsCI:                false,
                UseAzureCLI:         true,
        }
}</span>

// LoadConfig loads configuration from environment variables
func LoadConfig() *Config <span class="cov8" title="1">{
        config := DefaultConfig()

        // Load categories from TEST_CATEGORIES
        if categories := os.Getenv("TEST_CATEGORIES"); categories != "" </span><span class="cov8" title="1">{
                config.Categories = parseCategories(categories)
        }</span>

        // Skip flags
        <span class="cov8" title="1">config.SkipGoldenSnapshot = parseBool(os.Getenv("SKIP_GOLDEN_SNAPSHOT"), false)
        config.SkipPoolTests = parseBool(os.Getenv("SKIP_POOL_TESTS"), false)
        config.SkipE2ETests = parseBool(os.Getenv("SKIP_E2E_TESTS"), false)

        // Resource configuration
        if prefix := os.Getenv("TEST_RESOURCE_GROUP_PREFIX"); prefix != "" </span><span class="cov0" title="0">{
                config.ResourceGroupPrefix = prefix
        }</span>
        <span class="cov8" title="1">if location := os.Getenv("TEST_LOCATION"); location != "" </span><span class="cov0" title="0">{
                config.Location = location
        }</span>
        <span class="cov8" title="1">if timeout := os.Getenv("TEST_CLEANUP_TIMEOUT"); timeout != "" </span><span class="cov0" title="0">{
                if d, err := time.ParseDuration(timeout); err == nil </span><span class="cov0" title="0">{
                        config.CleanupTimeout = d
                }</span>
        }

        // Execution configuration
        <span class="cov8" title="1">if limit := os.Getenv("TEST_PARALLEL_LIMIT"); limit != "" </span><span class="cov0" title="0">{
                if i, err := strconv.Atoi(limit); err == nil </span><span class="cov0" title="0">{
                        config.ParallelLimit = i
                }</span>
        }
        <span class="cov8" title="1">if timeout := os.Getenv("TEST_TIMEOUT"); timeout != "" </span><span class="cov0" title="0">{
                if d, err := time.ParseDuration(timeout); err == nil </span><span class="cov0" title="0">{
                        config.TestTimeout = d
                }</span>
        }

        // CI detection
        <span class="cov8" title="1">config.IsCI = parseBool(os.Getenv("CI"), false) ||
                parseBool(os.Getenv("GITHUB_ACTIONS"), false) ||
                parseBool(os.Getenv("AZURE_DEVOPS"), false)

        // Azure configuration
        config.UseAzureCLI = os.Getenv("AZURE_CLIENT_ID") == ""

        // CI-specific adjustments
        if config.IsCI </span><span class="cov0" title="0">{
                config.ParallelLimit = 2 // More conservative in CI
                config.TestTimeout = 90 * time.Minute
        }</span>

        <span class="cov8" title="1">return config</span>
}

// ShouldRunCategory returns true if the given category should be executed
func (c *Config) ShouldRunCategory(category Category) bool <span class="cov8" title="1">{
        // Check skip flags first
        switch category </span>{
        case CategoryGolden:<span class="cov0" title="0">
                if c.SkipGoldenSnapshot </span><span class="cov0" title="0">{
                        return false
                }</span>
        case CategoryPool:<span class="cov0" title="0">
                if c.SkipPoolTests </span><span class="cov0" title="0">{
                        return false
                }</span>
        case CategoryE2E:<span class="cov0" title="0">
                if c.SkipE2ETests </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // Check if category is in the allowed list
        <span class="cov8" title="1">for _, allowed := range c.Categories </span><span class="cov8" title="1">{
                if allowed == category </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// AllCategories returns all available test categories
func AllCategories() []Category <span class="cov0" title="0">{
        return []Category{
                CategoryUnit,
                CategoryClient,
                CategoryIntegration,
                CategoryCompute,
                CategoryGolden,
                CategoryPool,
                CategoryE2E,
        }
}</span>

// FastCategories returns categories that run quickly (&lt; 2 minutes)
func FastCategories() []Category <span class="cov0" title="0">{
        return []Category{
                CategoryUnit,
                CategoryClient,
        }
}</span>

// SlowCategories returns categories that take significant time (&gt; 10 minutes)
func SlowCategories() []Category <span class="cov0" title="0">{
        return []Category{
                CategoryCompute,
                CategoryGolden,
                CategoryPool,
                CategoryE2E,
        }
}</span>

// parseCategories parses a comma-separated list of categories
func parseCategories(categoriesStr string) []Category <span class="cov8" title="1">{
        if categoriesStr == "all" </span><span class="cov0" title="0">{
                return AllCategories()
        }</span>
        <span class="cov8" title="1">if categoriesStr == "fast" </span><span class="cov0" title="0">{
                return FastCategories()
        }</span>
        <span class="cov8" title="1">if categoriesStr == "slow" </span><span class="cov0" title="0">{
                return SlowCategories()
        }</span>

        <span class="cov8" title="1">var categories []Category
        for _, cat := range strings.Split(categoriesStr, ",") </span><span class="cov8" title="1">{
                cat = strings.TrimSpace(cat)
                if cat != "" </span><span class="cov8" title="1">{
                        categories = append(categories, Category(cat))
                }</span>
        }
        <span class="cov8" title="1">return categories</span>
}

// parseBool parses a string to bool with default fallback
func parseBool(s string, defaultValue bool) bool <span class="cov8" title="1">{
        if s == "" </span><span class="cov8" title="1">{
                return defaultValue
        }</span>
        <span class="cov0" title="0">val, err := strconv.ParseBool(s)
        if err != nil </span><span class="cov0" title="0">{
                return defaultValue
        }</span>
        <span class="cov0" title="0">return val</span>
}

// GetEstimatedDuration returns the estimated duration for a category
func GetEstimatedDuration(category Category) time.Duration <span class="cov0" title="0">{
        switch category </span>{
        case CategoryUnit:<span class="cov0" title="0">
                return 30 * time.Second</span>
        case CategoryClient:<span class="cov0" title="0">
                return 2 * time.Minute</span>
        case CategoryIntegration:<span class="cov0" title="0">
                return 10 * time.Minute</span>
        case CategoryCompute:<span class="cov0" title="0">
                return 15 * time.Minute</span>
        case CategoryGolden:<span class="cov0" title="0">
                return 30 * time.Minute</span>
        case CategoryPool:<span class="cov0" title="0">
                return 30 * time.Minute</span>
        case CategoryE2E:<span class="cov0" title="0">
                return 45 * time.Minute</span>
        default:<span class="cov0" title="0">
                return 5 * time.Minute</span>
        }
}
</pre>
		
		<pre class="file" id="file17" style="display: none">package test

import (
        "context"
        "crypto/rand"
        "crypto/sha256"
        "encoding/base64"
        "encoding/hex"
        "fmt"
        "log/slog"
        "os/exec"
        "strings"
        "testing"
        "time"

        "shellbox/internal/infra"
        "shellbox/internal/sshutil"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/compute/armcompute/v6"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/network/armnetwork/v7"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armresources"
        "github.com/google/uuid"
)

// GoldenConfig holds configuration information for golden tests
type GoldenConfig struct {
        ResourceGroupName string
        Suffix            string
        Location          string
}

// SetupTest creates test environment and returns clients, config, and cleanup function
func SetupTest(t testing.TB, category Category) (*infra.AzureClients, *GoldenConfig, func()) <span class="cov0" title="0">{
        env := SetupTestEnvironment(t.(*testing.T), category)

        testConfig := &amp;GoldenConfig{
                ResourceGroupName: env.ResourceGroupName,
                Suffix:            env.Suffix,
                Location:          env.Config.Location,
        }

        return env.Clients, testConfig, env.Cleanup
}</span>

// DecodeBase64Script decodes a base64-encoded script and returns the content
func DecodeBase64Script(script string) (string, error) <span class="cov0" title="0">{
        decoded, err := base64.StdEncoding.DecodeString(script)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to decode base64 script: %w", err)
        }</span>
        <span class="cov0" title="0">return string(decoded), nil</span>
}

// GenerateSnapshotName generates a content-based snapshot name for testing
func GenerateSnapshotName() (string, error) <span class="cov0" title="0">{
        // Since generateGoldenSnapshotName is not exported, we'll implement a test version
        config := infra.QEMUScriptConfig{
                SSHPublicKey:  "sample-key-for-hashing",
                WorkingDir:    "/mnt/userdata",
                SSHPort:       infra.BoxSSHPort,
                MountDataDisk: true,
        }

        scriptContent, err := infra.GenerateQEMUInitScript(config)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to generate script for hashing: %w", err)
        }</span>

        // Hash the script content to create a unique identifier
        <span class="cov0" title="0">hasher := sha256.New()
        hasher.Write([]byte(scriptContent))
        hash := hex.EncodeToString(hasher.Sum(nil))[:12] // Use first 12 chars

        return fmt.Sprintf("golden-qemu-%s", hash), nil</span>
}

// EnsureGoldenResourceGroup ensures the golden snapshot resource group exists
func EnsureGoldenResourceGroup(ctx context.Context, clients *infra.AzureClients) error <span class="cov0" title="0">{
        // Implement the same logic as the unexported function
        slog.Info("Ensuring persistent resource group exists", "resourceGroup", infra.GoldenSnapshotResourceGroup)

        // Check if resource group already exists
        _, err := clients.ResourceClient.Get(ctx, infra.GoldenSnapshotResourceGroup, nil)
        if err == nil </span><span class="cov0" title="0">{
                slog.Info("Persistent resource group already exists", "resourceGroup", infra.GoldenSnapshotResourceGroup)
                return nil
        }</span>

        // Create the resource group
        <span class="cov0" title="0">slog.Info("Creating persistent resource group", "resourceGroup", infra.GoldenSnapshotResourceGroup)
        _, err = clients.ResourceClient.CreateOrUpdate(ctx, infra.GoldenSnapshotResourceGroup, armresources.ResourceGroup{
                Location: to.Ptr(infra.Location),
                Tags: map[string]*string{
                        infra.GoldenTagKeyPurpose: to.Ptr("golden-snapshots"),
                        infra.GoldenTagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                        infra.GoldenTagKeyRole:    to.Ptr("persistent-resource-group"),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create persistent resource group: %w", err)
        }</span>

        <span class="cov0" title="0">slog.Info("Created persistent resource group", "resourceGroup", infra.GoldenSnapshotResourceGroup)
        return nil</span>
}

// TempBoxInfo holds information about a temporary box created for golden snapshot
type TempBoxInfo struct {
        VMName     string
        DataDiskID string
        PrivateIP  string
        PublicIP   string
        NICName    string
        NSGName    string
        DiskName   string
}

// CreateTempBox creates a temporary VM for golden snapshot preparation
func CreateTempBox(ctx context.Context, clients *infra.AzureClients, resourceGroup, vmName string) (*TempBoxInfo, error) <span class="cov0" title="0">{
        // Implement simplified version for testing
        namer := infra.NewResourceNamer("test")

        // Create data volume
        dataDiskName := fmt.Sprintf("%s-data", vmName)
        now := time.Now().UTC()

        diskParams := armcompute.Disk{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armcompute.DiskProperties{
                        DiskSizeGB: to.Ptr(int32(infra.DefaultVolumeSizeGB)),
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption: to.Ptr(armcompute.DiskCreateOptionEmpty),
                        },
                },
                Tags: map[string]*string{
                        infra.GoldenTagKeyRole:    to.Ptr("temp-data-disk"),
                        infra.GoldenTagKeyPurpose: to.Ptr("golden-snapshot-creation"),
                        infra.GoldenTagKeyCreated: to.Ptr(now.Format(time.RFC3339)),
                        infra.GoldenTagKeyStage:   to.Ptr("creating"),
                },
        }

        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, resourceGroup, dataDiskName, diskParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start data volume creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create data volume: %w", err)
        }</span>

        // Create instance for temp box (simplified)
        <span class="cov0" title="0">instance, err := CreateTestInstance(ctx, clients, resourceGroup, vmName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create temp box instance: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;TempBoxInfo{
                VMName:     vmName,
                DataDiskID: *result.ID,
                PrivateIP:  instance.PrivateIP,
                NICName:    namer.BoxNICName(vmName),
                NSGName:    namer.BoxNSGName(vmName),
                DiskName:   dataDiskName,
        }, nil</span>
}

// CreateTestVolume creates a test volume with the specified size
func CreateTestVolume(ctx context.Context, clients *infra.AzureClients, resourceGroup, volumeName string, sizeGB int32) (*infra.VolumeInfo, error) <span class="cov0" title="0">{
        tags := infra.VolumeTags{
                Role:      "test-volume",
                Status:    "free",
                VolumeID:  uuid.New().String(),
                CreatedAt: time.Now().Format(time.RFC3339),
                LastUsed:  time.Now().Format(time.RFC3339),
        }

        diskParams := armcompute.Disk{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armcompute.DiskProperties{
                        DiskSizeGB: to.Ptr(sizeGB),
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption: to.Ptr(armcompute.DiskCreateOptionEmpty),
                        },
                },
                Tags: volumeTagsToMap(tags),
        }

        poller, err := clients.DisksClient.BeginCreateOrUpdate(ctx, resourceGroup, volumeName, diskParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start volume creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create volume: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;infra.VolumeInfo{
                Name:       *result.Name,
                ResourceID: *result.ID,
                Location:   *result.Location,
                SizeGB:     *result.Properties.DiskSizeGB,
                VolumeID:   tags.VolumeID,
                Tags:       tags,
        }, nil</span>
}

// CreateSnapshotFromVolume creates a snapshot from an existing volume
func CreateSnapshotFromVolume(ctx context.Context, clients *infra.AzureClients, resourceGroup, snapshotName, sourceResourceID string) (*infra.GoldenSnapshotInfo, error) <span class="cov0" title="0">{
        snapshotParams := armcompute.Snapshot{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armcompute.SnapshotProperties{
                        CreationData: &amp;armcompute.CreationData{
                                CreateOption:     to.Ptr(armcompute.DiskCreateOptionCopy),
                                SourceResourceID: to.Ptr(sourceResourceID),
                        },
                },
                Tags: map[string]*string{
                        infra.GoldenTagKeyRole:    to.Ptr("test-snapshot"),
                        infra.GoldenTagKeyPurpose: to.Ptr("test-snapshot-creation"),
                        infra.GoldenTagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                        infra.GoldenTagKeyStage:   to.Ptr("ready"),
                },
        }

        poller, err := clients.SnapshotsClient.BeginCreateOrUpdate(ctx, resourceGroup, snapshotName, snapshotParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start snapshot creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create snapshot: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;infra.GoldenSnapshotInfo{
                Name:         *result.Name,
                ResourceID:   *result.ID,
                Location:     *result.Location,
                CreatedTime:  *result.Properties.TimeCreated,
                SizeGB:       *result.Properties.DiskSizeGB,
                SourceDiskID: sourceResourceID,
        }, nil</span>
}

// WaitForQEMUSSH waits for SSH to become available on a QEMU instance
func WaitForQEMUSSH(ctx context.Context, instanceIP string, port int, timeout time.Duration) error <span class="cov0" title="0">{
        deadline := time.Now().Add(timeout)

        for time.Now().Before(deadline) </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                default:<span class="cov0" title="0"></span>
                }

                // Test SSH connectivity
                <span class="cov0" title="0">cmd := exec.CommandContext(ctx, "ssh",
                        "-o", "ConnectTimeout=5",
                        "-o", "StrictHostKeyChecking=no",
                        "-o", "BatchMode=yes",
                        "-p", fmt.Sprintf("%d", port),
                        fmt.Sprintf("ubuntu@%s", instanceIP),
                        "echo 'SSH test'")

                if err := cmd.Run(); err == nil </span><span class="cov0" title="0">{
                        return nil // SSH is working
                }</span>

                // Wait before retrying
                <span class="cov0" title="0">time.Sleep(10 * time.Second)</span>
        }

        <span class="cov0" title="0">return fmt.Errorf("timeout waiting for SSH on %s:%d", instanceIP, port)</span>
}

// ExecuteQEMUCommand executes a command on a QEMU instance via SSH
func ExecuteQEMUCommand(ctx context.Context, instanceIP string, port int, command string) error <span class="cov0" title="0">{
        sshCmd := exec.CommandContext(ctx, "ssh",
                "-o", "ConnectTimeout=10",
                "-o", "StrictHostKeyChecking=no",
                "-p", fmt.Sprintf("%d", port),
                fmt.Sprintf("ubuntu@%s", instanceIP),
                command)

        if err := sshCmd.Run(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to execute command on QEMU: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// ExecuteQEMUCommandWithOutput executes a command on a QEMU instance and returns output
func ExecuteQEMUCommandWithOutput(ctx context.Context, instanceIP string, port int, command string) (string, error) <span class="cov0" title="0">{
        sshCmd := exec.CommandContext(ctx, "ssh",
                "-o", "ConnectTimeout=10",
                "-o", "StrictHostKeyChecking=no",
                "-p", fmt.Sprintf("%d", port),
                fmt.Sprintf("ubuntu@%s", instanceIP),
                command)

        output, err := sshCmd.CombinedOutput()
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to execute command on QEMU: %w", err)
        }</span>

        <span class="cov0" title="0">return string(output), nil</span>
}

// GenerateTestResourceName generates a unique test resource name with a prefix
func GenerateTestResourceName(prefix string) string <span class="cov0" title="0">{
        // Generate random suffix
        bytes := make([]byte, 4)
        if _, err := rand.Read(bytes); err != nil </span><span class="cov0" title="0">{
                slog.Warn("Failed to generate random bytes, using timestamp", "error", err)
                return fmt.Sprintf("%s-%d", prefix, time.Now().Unix())
        }</span>

        // Convert to hex and ensure valid Azure resource name
        <span class="cov0" title="0">suffix := fmt.Sprintf("%x", bytes)
        return fmt.Sprintf("%s-%s", prefix, suffix)</span>
}

// CreateTestInstance creates a test VM instance
func CreateTestInstance(ctx context.Context, clients *infra.AzureClients, resourceGroup, instanceName string) (*InstanceInfo, error) <span class="cov0" title="0">{
        // Use the existing instance creation logic but simplified for testing
        namer := infra.NewResourceNamer("test")

        // Create NSG for the instance
        nsgName := namer.BoxNSGName(instanceName)
        nsgResult, err := createTestInstanceNSG(ctx, clients, nsgName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create NSG: %w", err)
        }</span>

        // Create NIC for the instance
        <span class="cov0" title="0">nicName := namer.BoxNICName(instanceName)
        nicResult, err := createTestInstanceNIC(ctx, clients, nicName, nsgResult.ID)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create NIC: %w", err)
        }</span>

        // Load SSH key
        <span class="cov0" title="0">_, sshPublicKey, err := sshutil.LoadKeyPair(infra.BastionSSHKeyPath)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load SSH key: %w", err)
        }</span>

        // Create VM
        <span class="cov0" title="0">vmParams := armcompute.VirtualMachine{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armcompute.VirtualMachineProperties{
                        HardwareProfile: &amp;armcompute.HardwareProfile{
                                VMSize: to.Ptr(armcompute.VirtualMachineSizeTypes(infra.VMSize)),
                        },
                        StorageProfile: &amp;armcompute.StorageProfile{
                                ImageReference: &amp;armcompute.ImageReference{
                                        Publisher: to.Ptr(infra.VMPublisher),
                                        Offer:     to.Ptr(infra.VMOffer),
                                        SKU:       to.Ptr(infra.VMSku),
                                        Version:   to.Ptr(infra.VMVersion),
                                },
                                OSDisk: &amp;armcompute.OSDisk{
                                        Name:         to.Ptr(fmt.Sprintf("%s-os", instanceName)),
                                        CreateOption: to.Ptr(armcompute.DiskCreateOptionTypesFromImage),
                                        ManagedDisk: &amp;armcompute.ManagedDiskParameters{
                                                StorageAccountType: to.Ptr(armcompute.StorageAccountTypesPremiumLRS),
                                        },
                                },
                        },
                        OSProfile: &amp;armcompute.OSProfile{
                                ComputerName:  to.Ptr(instanceName),
                                AdminUsername: to.Ptr(infra.AdminUsername),
                                LinuxConfiguration: &amp;armcompute.LinuxConfiguration{
                                        DisablePasswordAuthentication: to.Ptr(true),
                                        SSH: &amp;armcompute.SSHConfiguration{
                                                PublicKeys: []*armcompute.SSHPublicKey{
                                                        {
                                                                Path:    to.Ptr(fmt.Sprintf("/home/%s/.ssh/authorized_keys", infra.AdminUsername)),
                                                                KeyData: to.Ptr(sshPublicKey),
                                                        },
                                                },
                                        },
                                },
                        },
                        NetworkProfile: &amp;armcompute.NetworkProfile{
                                NetworkInterfaces: []*armcompute.NetworkInterfaceReference{
                                        {
                                                ID: to.Ptr(*nicResult.ID),
                                        },
                                },
                        },
                },
                Tags: map[string]*string{
                        infra.TagKeyRole:    to.Ptr("test-instance"),
                        infra.TagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                },
        }

        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, resourceGroup, instanceName, vmParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to start VM creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create VM: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;InstanceInfo{
                Name:       *result.Name,
                ResourceID: *result.ID,
                Location:   *result.Location,
                PrivateIP:  *nicResult.Properties.IPConfigurations[0].Properties.PrivateIPAddress,
                Status:     "free",
        }, nil</span>
}

// InstanceInfo contains information about a created instance (for testing)
type InstanceInfo struct {
        Name       string
        ResourceID string
        Location   string
        PrivateIP  string
        Status     string
}

// volumeTagsToMap converts VolumeTags struct to Azure tags map format
func volumeTagsToMap(tags infra.VolumeTags) map[string]*string <span class="cov0" title="0">{
        return map[string]*string{
                infra.TagKeyRole:     to.Ptr(tags.Role),
                infra.TagKeyStatus:   to.Ptr(tags.Status),
                infra.TagKeyCreated:  to.Ptr(tags.CreatedAt),
                infra.TagKeyLastUsed: to.Ptr(tags.LastUsed),
                "volume_id":          to.Ptr(tags.VolumeID),
        }
}</span>

// createTestInstanceNSG creates a simplified NSG for testing
func createTestInstanceNSG(ctx context.Context, clients *infra.AzureClients, nsgName string) (*armnetwork.SecurityGroup, error) <span class="cov0" title="0">{
        nsgParams := armnetwork.SecurityGroup{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armnetwork.SecurityGroupPropertiesFormat{
                        SecurityRules: []*armnetwork.SecurityRule{
                                {
                                        Name: to.Ptr("AllowSSH"),
                                        Properties: &amp;armnetwork.SecurityRulePropertiesFormat{
                                                Protocol:                 to.Ptr(armnetwork.SecurityRuleProtocolTCP),
                                                SourceAddressPrefix:      to.Ptr("*"),
                                                SourcePortRange:          to.Ptr("*"),
                                                DestinationAddressPrefix: to.Ptr("*"),
                                                DestinationPortRange:     to.Ptr("22"),
                                                Access:                   to.Ptr(armnetwork.SecurityRuleAccessAllow),
                                                Priority:                 to.Ptr(int32(1000)),
                                                Direction:                to.Ptr(armnetwork.SecurityRuleDirectionInbound),
                                        },
                                },
                        },
                },
                Tags: map[string]*string{
                        infra.TagKeyRole:    to.Ptr("test-nsg"),
                        infra.TagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                },
        }

        poller, err := clients.NSGClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, nsgName, nsgParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting NSG creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating NSG: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;result.SecurityGroup, nil</span>
}

// createTestInstanceNIC creates a simplified NIC for testing
func createTestInstanceNIC(ctx context.Context, clients *infra.AzureClients, nicName string, nsgID *string) (*armnetwork.Interface, error) <span class="cov0" title="0">{
        nicParams := armnetwork.Interface{
                Location: to.Ptr(infra.Location),
                Properties: &amp;armnetwork.InterfacePropertiesFormat{
                        NetworkSecurityGroup: &amp;armnetwork.SecurityGroup{
                                ID: nsgID,
                        },
                        IPConfigurations: []*armnetwork.InterfaceIPConfiguration{
                                {
                                        Name: to.Ptr("ipconfig1"),
                                        Properties: &amp;armnetwork.InterfaceIPConfigurationPropertiesFormat{
                                                Subnet: &amp;armnetwork.Subnet{
                                                        ID: to.Ptr(clients.BoxesSubnetID),
                                                },
                                                PrivateIPAllocationMethod: to.Ptr(armnetwork.IPAllocationMethodDynamic),
                                        },
                                },
                        },
                },
                Tags: map[string]*string{
                        infra.TagKeyRole:    to.Ptr("test-nic"),
                        infra.TagKeyCreated: to.Ptr(time.Now().Format(time.RFC3339)),
                },
        }

        poller, err := clients.NICClient.BeginCreateOrUpdate(ctx, clients.ResourceGroupName, nicName, nicParams, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("starting NIC creation: %w", err)
        }</span>

        <span class="cov0" title="0">result, err := poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("creating NIC: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;result.Interface, nil</span>
}

// GenerateQEMUResumeCommand generates a QEMU resume command for testing
func GenerateQEMUResumeCommand(workingDir string, port int) string <span class="cov0" title="0">{
        return fmt.Sprintf(`
# Mount data disk if not already mounted
if ! mountpoint -q /mnt/userdata; then
    sudo mkdir -p /mnt/userdata
    sudo mount /dev/disk/azure/scsi1/lun0 /mnt/userdata
fi

# Resume QEMU VM from saved state
sudo qemu-system-x86_64 \
   -enable-kvm \
   -m 24G \
   -mem-prealloc \
   -mem-path %s/qemu-memory/ubuntu-mem \
   -smp 8 \
   -cpu host \
   -drive file=%s/qemu-disks/ubuntu-base.qcow2,format=qcow2 \
   -drive file=%s/qemu-disks/cloud-init.iso,format=raw \
   -nographic \
   -monitor unix:/tmp/qemu-monitor.sock,server,nowait \
   -nic user,model=virtio,hostfwd=tcp::%d-:22,dns=8.8.8.8 \
   -loadvm ssh-ready &amp;
`, workingDir, workingDir, workingDir, port)
}</span>

// GenerateQEMUSaveStateCommand generates a QEMU save state command for testing
func GenerateQEMUSaveStateCommand(stateName string) string <span class="cov0" title="0">{
        return fmt.Sprintf(`echo -e "savevm %s\nquit" | sudo socat - UNIX-CONNECT:/tmp/qemu-monitor.sock`, stateName)
}</span>

// GenerateQEMULoadStateCommand generates a QEMU load state command for testing
func GenerateQEMULoadStateCommand(workingDir string, port int, stateName string) string <span class="cov0" title="0">{
        return fmt.Sprintf(`
# Mount data disk if not already mounted
if ! mountpoint -q /mnt/userdata; then
    sudo mkdir -p /mnt/userdata
    sudo mount /dev/disk/azure/scsi1/lun0 /mnt/userdata
fi

# Resume QEMU VM from specified state
sudo qemu-system-x86_64 \
   -enable-kvm \
   -m 24G \
   -mem-prealloc \
   -mem-path %s/qemu-memory/ubuntu-mem \
   -smp 8 \
   -cpu host \
   -drive file=%s/qemu-disks/ubuntu-base.qcow2,format=qcow2 \
   -drive file=%s/qemu-disks/cloud-init.iso,format=raw \
   -nographic \
   -monitor unix:/tmp/qemu-monitor.sock,server,nowait \
   -nic user,model=virtio,hostfwd=tcp::%d-:22,dns=8.8.8.8 \
   -loadvm %s &amp;
`, workingDir, workingDir, workingDir, port, stateName)
}</span>

// MockQEMUManager provides test-only QEMU operations for golden tests
type MockQEMUManager struct {
        clients *infra.AzureClients
}

// NewMockQEMUManager creates a mock QEMU manager for testing
func NewMockQEMUManager(clients *infra.AzureClients) *MockQEMUManager <span class="cov0" title="0">{
        return &amp;MockQEMUManager{
                clients: clients,
        }
}</span>

// SaveState simulates saving QEMU state for testing
func (m *MockQEMUManager) SaveState(_ context.Context, instanceIP, stateName string) error <span class="cov0" title="0">{
        // For testing, we'll simulate the save command
        saveCmd := GenerateQEMUSaveStateCommand(stateName)
        slog.Debug("Simulating QEMU save state", "stateName", stateName, "instanceIP", instanceIP)
        slog.Debug("QEMU save command", "command", saveCmd)

        // In a real implementation, this would execute the command via SSH
        // For testing, we'll just validate the parameters and return success/error
        if instanceIP == "" || stateName == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid parameters: instanceIP=%s, stateName=%s", instanceIP, stateName)
        }</span>

        // Simulate errors for specific test scenarios
        <span class="cov0" title="0">if instanceIP == "10.0.0.1" &amp;&amp; stateName == "test-state" </span><span class="cov0" title="0">{
                return fmt.Errorf("QEMU not running on instance %s", instanceIP)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// StartQEMUWithVolume simulates starting QEMU for testing
func (m *MockQEMUManager) StartQEMUWithVolume(_ context.Context, instanceIP, volumeID string) error <span class="cov0" title="0">{
        slog.Debug("Simulating QEMU start with volume", "volumeID", volumeID, "instanceIP", instanceIP)

        if instanceIP == "" || volumeID == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid parameters: instanceIP=%s, volumeID=%s", instanceIP, volumeID)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// StopQEMU simulates stopping QEMU for testing
func (m *MockQEMUManager) StopQEMU(_ context.Context, instanceIP string) error <span class="cov0" title="0">{
        slog.Debug("Simulating QEMU stop", "instanceIP", instanceIP)

        if instanceIP == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid instanceIP: %s", instanceIP)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// DetachVolumeFromInstance detaches a volume from an instance for testing
func DetachVolumeFromInstance(ctx context.Context, clients *infra.AzureClients, instanceID, volumeID string) error <span class="cov0" title="0">{
        // Extract instance name from resource ID
        parts := strings.Split(instanceID, "/")
        instanceName := parts[len(parts)-1]

        parts = strings.Split(volumeID, "/")
        resourceGroupName := ""
        for i, part := range parts </span><span class="cov0" title="0">{
                if part == "resourceGroups" &amp;&amp; i+1 &lt; len(parts) </span><span class="cov0" title="0">{
                        resourceGroupName = parts[i+1]
                        break</span>
                }
        }

        // Get current VM configuration
        <span class="cov0" title="0">vm, err := clients.ComputeClient.Get(ctx, resourceGroupName, instanceName, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get VM for volume detachment: %w", err)
        }</span>

        // Remove the specified data disk
        <span class="cov0" title="0">var newDataDisks []*armcompute.DataDisk
        for _, disk := range vm.Properties.StorageProfile.DataDisks </span><span class="cov0" title="0">{
                if disk.ManagedDisk != nil &amp;&amp; disk.ManagedDisk.ID != nil &amp;&amp; *disk.ManagedDisk.ID != volumeID </span><span class="cov0" title="0">{
                        newDataDisks = append(newDataDisks, disk)
                }</span>
        }

        // Update VM with new data disk configuration
        <span class="cov0" title="0">vm.Properties.StorageProfile.DataDisks = newDataDisks

        poller, err := clients.ComputeClient.BeginCreateOrUpdate(ctx, resourceGroupName, instanceName, vm.VirtualMachine, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start VM update for volume detachment: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = poller.PollUntilDone(ctx, &amp;infra.DefaultPollOptions)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to detach volume from VM: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file18" style="display: none">package test

import (
        "context"
        "crypto/rand"
        "fmt"
        "log/slog"
        "math/big"
        "testing"
        "time"

        "github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
        "github.com/Azure/azure-sdk-for-go/sdk/resourcemanager/resources/armresources"

        "shellbox/internal/infra"
)

// Environment manages Azure resources for testing
type Environment struct {
        Config            *Config
        Clients           *infra.AzureClients
        Suffix            string
        ResourceGroupName string
        CreatedResources  []string
        t                 *testing.T
        startTime         time.Time
        cleanedUp         bool // Prevent double cleanup
}

// SetupTestEnvironment creates a new test environment with Azure resources
func SetupTestEnvironment(t *testing.T, category Category) *Environment <span class="cov0" title="0">{
        t.Helper()

        // Initialize logger with production configuration
        infra.SetDefaultLogger()

        config := LoadConfig()

        // Skip if category is not enabled
        if !config.ShouldRunCategory(category) </span><span class="cov0" title="0">{
                t.Skipf("Category %s is not enabled in test configuration", category)
        }</span>

        // Generate unique suffix for this test's resources
        <span class="cov0" title="0">rndNum, _ := rand.Int(rand.Reader, big.NewInt(100000))
        suffix := fmt.Sprintf("%s-%s-%d", config.ResourceGroupPrefix, category, rndNum.Int64())

        // Use shared resource group for all tests
        sharedRGName := "shellbox-testing"

        // Create Azure clients with the shared resource group
        clients := infra.NewAzureClients(suffix, config.UseAzureCLI)
        // Override the resource group name to use shared one
        clients.ResourceGroupName = sharedRGName

        env := &amp;Environment{
                Config:            config,
                Clients:           clients,
                Suffix:            suffix,
                ResourceGroupName: sharedRGName,
                CreatedResources:  []string{},
                t:                 t,
                startTime:         time.Now(),
                cleanedUp:         false,
        }

        // Create the test resource group
        if err := env.createTestResourceGroup(); err != nil </span><span class="cov0" title="0">{
                t.Fatalf("Failed to create test resource group: %v", err)
        }</span>

        // Set up cleanup
        <span class="cov0" title="0">t.Cleanup(func() </span><span class="cov0" title="0">{
                env.Cleanup()
        }</span>)

        <span class="cov0" title="0">slog.Info("Test environment ready",
                "category", category,
                "suffix", suffix,
                "sharedResourceGroup", env.ResourceGroupName,
                "useAzureCLI", config.UseAzureCLI)

        return env</span>
}

// SetupMinimalTestEnvironment creates a lightweight test environment for unit tests
func SetupMinimalTestEnvironment(t *testing.T) *Environment <span class="cov8" title="1">{
        t.Helper()

        // Initialize logger with production configuration
        infra.SetDefaultLogger()

        config := LoadConfig()

        // Generate unique suffix but don't create Azure resources
        rndNum, _ := rand.Int(rand.Reader, big.NewInt(100000))
        suffix := fmt.Sprintf("%s-unit-%d", config.ResourceGroupPrefix, rndNum.Int64())

        env := &amp;Environment{
                Config:    config,
                Suffix:    suffix,
                t:         t,
                startTime: time.Now(),
        }

        return env
}</span>

// createTestResourceGroup creates or ensures the shared resource group exists (idempotent)
func (te *Environment) createTestResourceGroup() error <span class="cov0" title="0">{
        ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
        defer cancel()

        // Check if resource group already exists
        _, err := te.Clients.ResourceClient.Get(ctx, te.ResourceGroupName, nil)
        if err == nil </span><span class="cov0" title="0">{
                // Resource group already exists, we're good
                slog.Info("Shared resource group already exists", "name", te.ResourceGroupName)
                return nil
        }</span>

        // Resource group doesn't exist, create it
        <span class="cov0" title="0">slog.Info("Creating shared resource group", "name", te.ResourceGroupName)

        _, err = te.Clients.ResourceClient.CreateOrUpdate(ctx, te.ResourceGroupName, armresources.ResourceGroup{
                Location: to.Ptr(te.Config.Location),
                Tags: map[string]*string{
                        "purpose":     to.Ptr("integration-tests"),
                        "created":     to.Ptr(time.Now().Format(time.RFC3339)),
                        "description": to.Ptr("Shared resource group for all integration tests"),
                        "persistent":  to.Ptr("true"),
                },
        }, nil)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create shared resource group: %w", err)
        }</span>

        <span class="cov0" title="0">slog.Info("Successfully created shared resource group", "name", te.ResourceGroupName)
        // Don't add the RG to CreatedResources since we never want to delete it
        return nil</span>
}

// TrackResource adds a resource to the cleanup list
func (te *Environment) TrackResource(resourceName string) <span class="cov0" title="0">{
        te.CreatedResources = append(te.CreatedResources, resourceName)
}</span>

// Cleanup removes all test resources
func (te *Environment) Cleanup() <span class="cov0" title="0">{
        if te.Clients == nil || te.cleanedUp </span><span class="cov0" title="0">{
                return // Nothing to clean up for minimal environments or already cleaned up
        }</span>
        <span class="cov0" title="0">te.cleanedUp = true // Mark as cleaned up to prevent double cleanup

        elapsed := time.Since(te.startTime)
        category := te.getCurrentCategory()

        slog.Info("Starting test cleanup",
                "suffix", te.Suffix,
                "resources", len(te.CreatedResources),
                "elapsed", elapsed,
                "category", category)

        // Clean up table storage first (if tables were created with this suffix)
        if te.Clients.TableClient != nil </span><span class="cov0" title="0">{
                ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
                defer cancel()

                if err := infra.CleanupTestTables(ctx, te.Clients, te.Suffix); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to cleanup test tables", "suffix", te.Suffix, "error", err)
                }</span> else<span class="cov0" title="0"> {
                        slog.Info("Successfully cleaned up test tables", "suffix", te.Suffix)
                }</span>
        }

        // Clean up individual resources created by this test
        // Note: We don't delete the shared resource group - it's persistent
        <span class="cov0" title="0">if len(te.CreatedResources) &gt; 0 </span><span class="cov0" title="0">{
                slog.Info("Cleaning up individual test resources",
                        "count", len(te.CreatedResources),
                        "suffix", te.Suffix)

                // In practice, most tests will use Azure's resource lifecycle management
                // where deleting parent resources (like VMs) automatically cleans up dependent resources
                // Individual tests can also implement their own specific cleanup if needed

                for _, resourceName := range te.CreatedResources </span><span class="cov0" title="0">{
                        slog.Info("Resource tracked for cleanup", "resource", resourceName)
                }</span>

                <span class="cov0" title="0">slog.Info("Individual resource cleanup completed",
                        "suffix", te.Suffix,
                        "elapsed", time.Since(te.startTime))</span>
        } else<span class="cov0" title="0"> {
                slog.Info("No individual resources to clean up", "suffix", te.Suffix)
        }</span>
}

// WaitForResource waits for a resource to be ready
func (te *Environment) WaitForResource(ctx context.Context, resourceName string, checkFunc func() (bool, error)) error <span class="cov0" title="0">{
        return infra.RetryOperation(ctx, func(_ context.Context) error </span><span class="cov0" title="0">{
                ready, err := checkFunc()
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if !ready </span><span class="cov0" title="0">{
                        return fmt.Errorf("resource %s not ready yet", resourceName)
                }</span>
                <span class="cov0" title="0">return nil</span>
        }, 5*time.Minute, 10*time.Second, fmt.Sprintf("wait for resource %s", resourceName))
}

// GetResourceNamer returns a resource namer for this test environment
func (te *Environment) GetResourceNamer() *infra.ResourceNamer <span class="cov0" title="0">{
        return infra.NewResourceNamer(te.Suffix)
}</span>

// CleanupResourcesBySuffix deletes all resources in the resource group that match this test's suffix
func (te *Environment) CleanupResourcesBySuffix(ctx context.Context) error <span class="cov0" title="0">{
        if te.Clients == nil </span><span class="cov0" title="0">{
                return nil // Nothing to clean up for minimal environments
        }</span>

        <span class="cov0" title="0">slog.Info("Cleaning up resources by suffix", "suffix", te.Suffix, "resourceGroup", te.ResourceGroupName)

        // Clean up volumes/disks with matching suffix
        pager := te.Clients.DisksClient.NewListByResourceGroupPager(te.ResourceGroupName, nil)
        for pager.More() </span><span class="cov0" title="0">{
                page, err := pager.NextPage(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("listing disks for cleanup: %w", err)
                }</span>

                <span class="cov0" title="0">for _, disk := range page.Value </span><span class="cov0" title="0">{
                        if disk.Name != nil &amp;&amp; contains(*disk.Name, te.Suffix) </span><span class="cov0" title="0">{
                                slog.Info("Deleting disk", "name", *disk.Name, "suffix", te.Suffix)
                                if err := infra.DeleteVolume(ctx, te.Clients, te.ResourceGroupName, *disk.Name); err != nil </span><span class="cov0" title="0">{
                                        slog.Warn("Failed to delete disk", "name", *disk.Name, "error", err)
                                }</span>
                        }
                }
        }

        // TODO: Add cleanup for other resource types (VMs, NICs, etc.) if needed for tests

        <span class="cov0" title="0">return nil</span>
}

// GetUniqueResourceName generates a unique resource name for testing
func (te *Environment) GetUniqueResourceName(prefix string) string <span class="cov0" title="0">{
        rndNum, _ := rand.Int(rand.Reader, big.NewInt(1000))
        return fmt.Sprintf("%s-%s-%d", prefix, te.Suffix, rndNum.Int64())
}</span>

// getCurrentCategory extracts the category from the test name or suffix
func (te *Environment) getCurrentCategory() Category <span class="cov0" title="0">{
        testName := te.t.Name()

        // Try to extract category from test name
        for _, category := range AllCategories() </span><span class="cov0" title="0">{
                if contains(testName, string(category)) </span><span class="cov0" title="0">{
                        return category
                }</span>
        }

        // Fall back to extracting from suffix
        <span class="cov0" title="0">for _, category := range AllCategories() </span><span class="cov0" title="0">{
                if contains(te.Suffix, string(category)) </span><span class="cov0" title="0">{
                        return category
                }</span>
        }

        <span class="cov0" title="0">return CategoryUnit</span> // Default fallback
}

// contains checks if a string contains a substring (case-insensitive)
func contains(s, substr string) bool <span class="cov0" title="0">{
        return len(s) &gt;= len(substr) &amp;&amp;
                (s == substr ||
                        s[:len(substr)] == substr ||
                        s[len(s)-len(substr):] == substr ||
                        indexOf(s, substr) &gt;= 0)
}</span>

// indexOf returns the index of substr in s, or -1 if not found
func indexOf(s, substr string) int <span class="cov0" title="0">{
        for i := 0; i &lt;= len(s)-len(substr); i++ </span><span class="cov0" title="0">{
                if s[i:i+len(substr)] == substr </span><span class="cov0" title="0">{
                        return i
                }</span>
        }
        <span class="cov0" title="0">return -1</span>
}

// RequireCategory skips the test if the category is not enabled
func RequireCategory(t *testing.T, category Category) <span class="cov0" title="0">{
        t.Helper()

        config := LoadConfig()
        if !config.ShouldRunCategory(category) </span><span class="cov0" title="0">{
                t.Skipf("Test requires category %s which is not enabled", category)
        }</span>
}

// RequireAzure is deprecated - Azure tests always run
func RequireAzure(t *testing.T) <span class="cov0" title="0">{
        t.Helper()
        // Azure tests always run - no skipping
}</span>

// LogTestProgress logs progress during long-running tests
func LogTestProgress(t *testing.T, operation string, details ...interface{}) <span class="cov0" title="0">{
        t.Helper()

        args := []interface{}{"test", t.Name(), "operation", operation}
        args = append(args, details...)

        slog.Info("Test progress", args...)
}</span>
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
